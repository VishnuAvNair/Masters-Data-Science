{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM MLP with POS TAG (part 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>partition</th>\n",
       "      <th>abstract_id</th>\n",
       "      <th>seq</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>postaglist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>4293578</td>\n",
       "      <td>0</td>\n",
       "      <td>To investigate the efficacy of 6 weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at 12 weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .</td>\n",
       "      <td>OBJECTIVE</td>\n",
       "      <td>PART VERB DET NOUN ADP NUM NOUN ADP ADJ ADJ PUNCT NOUN ADJ NOUN ADP VERB NOUN PUNCT NOUN PUNCT CCONJ ADJ ADJ PUNCT NOUN NOUN ADP DET ADJ NOUN CCONJ ADP DET NOUN VERB VERB VERB ADP NUM NOUN ADP ADJ NOUN ADP ADJ ADP ADJ NOUN NOUN PUNCT PROPN PUNCT PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train</td>\n",
       "      <td>4293578</td>\n",
       "      <td>1</td>\n",
       "      <td>A total of 125 patients with primary knee OA were randomized 1:1 ; 63 received 7.5 mg/day of prednisolone and 62 received placebo for 6 weeks .</td>\n",
       "      <td>METHODS</td>\n",
       "      <td>DET NOUN ADP NUM NOUN ADP ADJ NOUN PROPN VERB VERB NUM PUNCT NUM VERB NUM NOUN SYM NOUN ADP NOUN CCONJ NUM VERB NOUN ADP NUM NOUN PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train</td>\n",
       "      <td>4293578</td>\n",
       "      <td>2</td>\n",
       "      <td>Outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .</td>\n",
       "      <td>METHODS</td>\n",
       "      <td>PROPN NOUN VERB NOUN NOUN CCONJ NOUN ADP NOUN NOUN CCONJ ADJ NOUN NOUN PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train</td>\n",
       "      <td>4293578</td>\n",
       "      <td>3</td>\n",
       "      <td>Pain was assessed using the visual analog pain scale ( 0-100 mm ) .</td>\n",
       "      <td>METHODS</td>\n",
       "      <td>PROPN VERB VERB VERB DET ADJ NOUN NOUN NOUN PUNCT NUM SYM NUM NOUN PUNCT PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train</td>\n",
       "      <td>4293578</td>\n",
       "      <td>4</td>\n",
       "      <td>Secondary outcome measures included the Western Ontario and McMaster Universities Osteoarthritis Index scores , patient global assessment ( PGA ) of the severity of knee OA , and 6-min walk distance ( 6MWD ) .</td>\n",
       "      <td>METHODS</td>\n",
       "      <td>ADJ NOUN NOUN VERB DET PROPN PROPN CCONJ PROPN PROPN PROPN PROPN NOUN PUNCT ADJ ADJ NOUN PUNCT PROPN PUNCT ADP DET NOUN ADP NOUN PROPN PUNCT CCONJ NUM NOUN NOUN PUNCT NOUN PUNCT PUNCT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  partition  abstract_id  seq  \\\n",
       "0     train      4293578    0   \n",
       "1     train      4293578    1   \n",
       "2     train      4293578    2   \n",
       "3     train      4293578    3   \n",
       "4     train      4293578    4   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                         text  \\\n",
       "0  To investigate the efficacy of 6 weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at 12 weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .   \n",
       "1                                                                                                                                             A total of 125 patients with primary knee OA were randomized 1:1 ; 63 received 7.5 mg/day of prednisolone and 62 received placebo for 6 weeks .   \n",
       "2                                                                                                                                                                             Outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .   \n",
       "3                                                                                                                                                                                                                         Pain was assessed using the visual analog pain scale ( 0-100 mm ) .   \n",
       "4                                                                           Secondary outcome measures included the Western Ontario and McMaster Universities Osteoarthritis Index scores , patient global assessment ( PGA ) of the severity of knee OA , and 6-min walk distance ( 6MWD ) .   \n",
       "\n",
       "       label  \\\n",
       "0  OBJECTIVE   \n",
       "1    METHODS   \n",
       "2    METHODS   \n",
       "3    METHODS   \n",
       "4    METHODS   \n",
       "\n",
       "                                                                                                                                                                                                                                                    postaglist  \n",
       "0  PART VERB DET NOUN ADP NUM NOUN ADP ADJ ADJ PUNCT NOUN ADJ NOUN ADP VERB NOUN PUNCT NOUN PUNCT CCONJ ADJ ADJ PUNCT NOUN NOUN ADP DET ADJ NOUN CCONJ ADP DET NOUN VERB VERB VERB ADP NUM NOUN ADP ADJ NOUN ADP ADJ ADP ADJ NOUN NOUN PUNCT PROPN PUNCT PUNCT  \n",
       "1                                                                                                                      DET NOUN ADP NUM NOUN ADP ADJ NOUN PROPN VERB VERB NUM PUNCT NUM VERB NUM NOUN SYM NOUN ADP NOUN CCONJ NUM VERB NOUN ADP NUM NOUN PUNCT  \n",
       "2                                                                                                                                                                                 PROPN NOUN VERB NOUN NOUN CCONJ NOUN ADP NOUN NOUN CCONJ ADJ NOUN NOUN PUNCT  \n",
       "3                                                                                                                                                                               PROPN VERB VERB VERB DET ADJ NOUN NOUN NOUN PUNCT NUM SYM NUM NOUN PUNCT PUNCT  \n",
       "4                                                                      ADJ NOUN NOUN VERB DET PROPN PROPN CCONJ PROPN PROPN PROPN PROPN NOUN PUNCT ADJ ADJ NOUN PUNCT PROPN PUNCT ADP DET NOUN ADP NOUN PROPN PUNCT CCONJ NUM NOUN NOUN PUNCT NOUN PUNCT PUNCT  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# file PubMed_20k_RCT.csv created by script01_create_single_dataset\n",
    "df_all = pd.read_csv('input/PubMed_20k_RCT_POS_TAG.csv')\n",
    "df_train = df_all[df_all['partition']=='train']\n",
    "df_valid = df_all[df_all['partition']=='dev']\n",
    "df_test = df_all[df_all['partition']=='test']\n",
    "pd.set_option('max_colwidth',500)\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train partition size: 180040\n",
      "Valid partition size: 30212\n",
      "Test partition size: 30135\n",
      "Total dataset size: 240387\n"
     ]
    }
   ],
   "source": [
    "X_train_cnt = df_train.shape[0]\n",
    "X_valid_cnt = df_valid.shape[0]\n",
    "X_test_cnt = df_test.shape[0]\n",
    "\n",
    "X_all = df_all.postaglist.values\n",
    "\n",
    "print('Train partition size: {}'.format(X_train_cnt))\n",
    "print('Valid partition size: {}'.format(X_valid_cnt))\n",
    "print('Test partition size: {}'.format(X_test_cnt))\n",
    "print('Total dataset size: {}'.format(X_all.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create token sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size = 15\n",
      "CPU times: user 10.4 s, sys: 90.3 ms, total: 10.4 s\n",
      "Wall time: 10.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# reduce vocabulary size to make problem manageable for available computing resources\n",
    "#SEQ_VOC = 50000\n",
    "#print('Number of tokens for sequences = {}'.format(SEQ_VOC))\n",
    "\n",
    "#tokenizer = Tokenizer(num_words=VOC_SIZE, filters='!\"*,./:;?@\\`|')\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_all)\n",
    "sequences = tokenizer.texts_to_sequences(X_all)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "VOC_SIZE = len(word_index)\n",
    "print('Vocabulary size = {}'.format(VOC_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adj': 5,\n",
       " 'adp': 3,\n",
       " 'adv': 10,\n",
       " 'cconj': 9,\n",
       " 'det': 7,\n",
       " 'intj': 15,\n",
       " 'noun': 1,\n",
       " 'num': 6,\n",
       " 'part': 12,\n",
       " 'pron': 14,\n",
       " 'propn': 8,\n",
       " 'punct': 2,\n",
       " 'sym': 11,\n",
       " 'verb': 4,\n",
       " 'x': 13}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3EAAAD8CAYAAADZsi3XAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18156e76d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seq_len = [len(seq) for seq in sequences]\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 4))\n",
    "axes[0].boxplot(seq_len)\n",
    "axes[1].hist(seq_len, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240387, 120)\n"
     ]
    }
   ],
   "source": [
    "MAX_SEQ_LEN = 120\n",
    "X_token_seq_all = pad_sequences(sequences, maxlen=MAX_SEQ_LEN, dtype='int32', padding='pre', truncating='post', value=0)\n",
    "print(X_token_seq_all.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize output labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.09 s, sys: 55 ms, total: 2.15 s\n",
      "Wall time: 2.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "labels = df_all.label.values\n",
    "label_dict = {label: no for no, label in enumerate(set(labels))}\n",
    "number_of_classes = len(label_dict)\n",
    "\n",
    "# get labels as integers\n",
    "y_all = [label_dict[label] for label in labels]\n",
    "\n",
    "# change y to categorical (vectorize output)\n",
    "y_all = np.array([to_categorical(i, num_classes=number_of_classes) for i in y_all])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240387, 120)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 8, 2, 2],\n",
       "       [0, 0, 0, ..., 6, 1, 2],\n",
       "       [0, 0, 0, ..., 1, 1, 2],\n",
       "       ..., \n",
       "       [0, 0, 0, ..., 1, 6, 2],\n",
       "       [0, 0, 0, ..., 4, 4, 2],\n",
       "       [0, 0, 0, ..., 8, 1, 2]], dtype=int32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_token_seq_all.shape)\n",
    "X_token_seq_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240387, 1800)\n",
      "(240387, 1800)\n",
      "CPU times: user 2min 6s, sys: 2.05 s, total: 2min 8s\n",
      "Wall time: 2min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "EMBEDDING_DIM = VOC_SIZE\n",
    "\n",
    "def get_vector(token):\n",
    "    vector = np.zeros(EMBEDDING_DIM)\n",
    "    if token != 0:\n",
    "        vector[token-1] = 1\n",
    "    return vector\n",
    "\n",
    "X_token_seq_all_v = np.zeros((X_token_seq_all.shape[0], X_token_seq_all.shape[1] * EMBEDDING_DIM))\n",
    "print(X_token_seq_all_v.shape)\n",
    "i = 0\n",
    "for token_seq in X_token_seq_all:\n",
    "    X_token_seq_all_v[i] = np.array([get_vector(token) for token in token_seq]).flatten()\n",
    "    i += 1\n",
    "    \n",
    "print(X_token_seq_all_v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240387, 15, 120)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 15, 120)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 75)                58800     \n",
      "_________________________________________________________________\n",
      "sentence_vector_1 (Dense)    (None, 100)               7600      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "sentence_vector_2 (Dense)    (None, 20)                2020      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 105       \n",
      "=================================================================\n",
      "Total params: 68,525\n",
      "Trainable params: 68,525\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 180040 samples, validate on 30212 samples\n",
      "Epoch 1/20\n",
      "180040/180040 [==============================] - 44s 245us/step - loss: 1.2153 - acc: 0.4849 - val_loss: 1.0545 - val_acc: 0.5704\n",
      "Epoch 2/20\n",
      "180040/180040 [==============================] - 59s 330us/step - loss: 1.0875 - acc: 0.5621 - val_loss: 0.9799 - val_acc: 0.6116\n",
      "Epoch 3/20\n",
      "180040/180040 [==============================] - 61s 337us/step - loss: 1.0377 - acc: 0.5882 - val_loss: 0.9379 - val_acc: 0.6283\n",
      "Epoch 4/20\n",
      "180040/180040 [==============================] - 61s 340us/step - loss: 1.0075 - acc: 0.6047 - val_loss: 0.9156 - val_acc: 0.6406\n",
      "Epoch 5/20\n",
      "180040/180040 [==============================] - 63s 350us/step - loss: 0.9855 - acc: 0.6164 - val_loss: 0.9029 - val_acc: 0.6473\n",
      "Epoch 6/20\n",
      "180040/180040 [==============================] - 61s 340us/step - loss: 0.9666 - acc: 0.6246 - val_loss: 0.8981 - val_acc: 0.6507\n",
      "Epoch 7/20\n",
      "180040/180040 [==============================] - 61s 339us/step - loss: 0.9518 - acc: 0.6315 - val_loss: 0.8921 - val_acc: 0.6524\n",
      "Epoch 8/20\n",
      "180040/180040 [==============================] - 62s 347us/step - loss: 0.9404 - acc: 0.6381 - val_loss: 0.8853 - val_acc: 0.6560\n",
      "Epoch 9/20\n",
      "180040/180040 [==============================] - 60s 333us/step - loss: 0.9301 - acc: 0.6432 - val_loss: 0.8843 - val_acc: 0.6550\n",
      "Epoch 10/20\n",
      "180040/180040 [==============================] - 59s 330us/step - loss: 0.9195 - acc: 0.6478 - val_loss: 0.8826 - val_acc: 0.6592\n",
      "Epoch 11/20\n",
      "180040/180040 [==============================] - 60s 333us/step - loss: 0.9111 - acc: 0.6507 - val_loss: 0.8783 - val_acc: 0.6600\n",
      "Epoch 12/20\n",
      "180040/180040 [==============================] - 59s 330us/step - loss: 0.9033 - acc: 0.6543 - val_loss: 0.8827 - val_acc: 0.6604\n",
      "CPU times: user 28min 58s, sys: 2min 12s, total: 31min 10s\n",
      "Wall time: 11min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Bidirectional, LSTM, Flatten, Dropout, Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "WINDOW = 1   # number of tokens in one timestep\n",
    "TIMESTEP = EMBEDDING_DIM * WINDOW\n",
    "TIME_LENGTH = int(MAX_SEQ_LEN / WINDOW)\n",
    "\n",
    "# reshape input \n",
    "X_seq_input = X_token_seq_all_v.reshape(X_token_seq_all_v.shape[0], TIMESTEP, TIME_LENGTH)\n",
    "\n",
    "print(X_seq_input.shape)\n",
    "\n",
    "sequence_input = Input(shape=(TIMESTEP, TIME_LENGTH), dtype='float32')\n",
    "lstm = LSTM(units=TIMESTEP * 5, return_sequences=False)(sequence_input)\n",
    "D1 = Dense(100, activation='relu', name='sentence_vector_1')(lstm)\n",
    "D1 = Dropout(0.5)(D1)\n",
    "D1 = Dense(20, activation='relu', name='sentence_vector_2')(D1)\n",
    "D1 = Dropout(0.5)(D1)\n",
    "preds = Dense(len(label_dict), activation='softmax')(D1)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# learn\n",
    "model.fit(X_seq_input[:X_train_cnt], y_all[:X_train_cnt], \\\n",
    "          validation_data=(X_seq_input[X_train_cnt:(X_train_cnt+X_valid_cnt)], \\\n",
    "                                 y_all[X_train_cnt:(X_train_cnt+X_valid_cnt)]), \\\n",
    "          callbacks=[EarlyStopping(patience=1, monitor='val_loss')], \\\n",
    "          verbose=1, epochs=20, batch_size=256)\n",
    "\n",
    "model1 = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240387, 45, 40)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 45, 40)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 225)               239400    \n",
      "_________________________________________________________________\n",
      "sentence_vector_1 (Dense)    (None, 100)               22600     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "sentence_vector_2 (Dense)    (None, 20)                2020      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 105       \n",
      "=================================================================\n",
      "Total params: 264,125\n",
      "Trainable params: 264,125\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 180040 samples, validate on 30212 samples\n",
      "Epoch 1/20\n",
      "180040/180040 [==============================] - 618s 3ms/step - loss: 1.2687 - acc: 0.4630 - val_loss: 1.1133 - val_acc: 0.5395\n",
      "Epoch 2/20\n",
      "180040/180040 [==============================] - 612s 3ms/step - loss: 1.1192 - acc: 0.5396 - val_loss: 1.0249 - val_acc: 0.5909\n",
      "Epoch 3/20\n",
      "180040/180040 [==============================] - 608s 3ms/step - loss: 1.0587 - acc: 0.5757 - val_loss: 0.9742 - val_acc: 0.6118\n",
      "Epoch 4/20\n",
      "180040/180040 [==============================] - 610s 3ms/step - loss: 1.0218 - acc: 0.5969 - val_loss: 0.9340 - val_acc: 0.6310\n",
      "Epoch 5/20\n",
      "180040/180040 [==============================] - 607s 3ms/step - loss: 0.9931 - acc: 0.6107 - val_loss: 0.9185 - val_acc: 0.6356\n",
      "Epoch 6/20\n",
      "180040/180040 [==============================] - 693s 4ms/step - loss: 0.9708 - acc: 0.6230 - val_loss: 0.8973 - val_acc: 0.6471\n",
      "Epoch 7/20\n",
      "180040/180040 [==============================] - 755s 4ms/step - loss: 0.9510 - acc: 0.6326 - val_loss: 0.8806 - val_acc: 0.6543\n",
      "Epoch 8/20\n",
      "180040/180040 [==============================] - 568s 3ms/step - loss: 0.9337 - acc: 0.6395 - val_loss: 0.8712 - val_acc: 0.6599\n",
      "Epoch 9/20\n",
      "180040/180040 [==============================] - 566s 3ms/step - loss: 0.9180 - acc: 0.6464 - val_loss: 0.8658 - val_acc: 0.6639\n",
      "Epoch 10/20\n",
      "180040/180040 [==============================] - 565s 3ms/step - loss: 0.9012 - acc: 0.6536 - val_loss: 0.8631 - val_acc: 0.6647\n",
      "Epoch 11/20\n",
      "180040/180040 [==============================] - 562s 3ms/step - loss: 0.8859 - acc: 0.6619 - val_loss: 0.8585 - val_acc: 0.6688\n",
      "Epoch 12/20\n",
      "180040/180040 [==============================] - 568s 3ms/step - loss: 0.8732 - acc: 0.6672 - val_loss: 0.8581 - val_acc: 0.6681\n",
      "Epoch 13/20\n",
      "180040/180040 [==============================] - 566s 3ms/step - loss: 0.8559 - acc: 0.6733 - val_loss: 0.8598 - val_acc: 0.6690\n",
      "CPU times: user 5h 39min 19s, sys: 53min 46s, total: 6h 33min 5s\n",
      "Wall time: 2h 11min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Bidirectional, LSTM, Flatten, Dropout, Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "WINDOW = 3   # number of tokens in one timestep\n",
    "TIMESTEP = EMBEDDING_DIM * WINDOW\n",
    "TIME_LENGTH = int(MAX_SEQ_LEN / WINDOW)\n",
    "\n",
    "# reshape input \n",
    "X_seq_input = X_token_seq_all_v.reshape(X_token_seq_all_v.shape[0], TIMESTEP, TIME_LENGTH)\n",
    "\n",
    "print(X_seq_input.shape)\n",
    "\n",
    "sequence_input = Input(shape=(TIMESTEP, TIME_LENGTH), dtype='float32')\n",
    "lstm = LSTM(units=TIMESTEP * 5, return_sequences=False)(sequence_input)\n",
    "D1 = Dense(100, activation='relu', name='sentence_vector_1')(lstm)\n",
    "D1 = Dropout(0.5)(D1)\n",
    "D1 = Dense(20, activation='relu', name='sentence_vector_2')(D1)\n",
    "D1 = Dropout(0.5)(D1)\n",
    "preds = Dense(len(label_dict), activation='softmax')(D1)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# learn\n",
    "model.fit(X_seq_input[:X_train_cnt], y_all[:X_train_cnt], \\\n",
    "          validation_data=(X_seq_input[X_train_cnt:(X_train_cnt+X_valid_cnt)], \\\n",
    "                                 y_all[X_train_cnt:(X_train_cnt+X_valid_cnt)]), \\\n",
    "          callbacks=[EarlyStopping(patience=1, monitor='val_loss')], \\\n",
    "          verbose=1, epochs=20, batch_size=256)\n",
    "\n",
    "model2 = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240387, 75, 24)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 75, 24)            0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 375)               600000    \n",
      "_________________________________________________________________\n",
      "sentence_vector_1 (Dense)    (None, 100)               37600     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "sentence_vector_2 (Dense)    (None, 20)                2020      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 105       \n",
      "=================================================================\n",
      "Total params: 639,725\n",
      "Trainable params: 639,725\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 180040 samples, validate on 30212 samples\n",
      "Epoch 1/20\n",
      "180040/180040 [==============================] - 2080s 12ms/step - loss: 1.2841 - acc: 0.4437 - val_loss: 1.1326 - val_acc: 0.5198\n",
      "Epoch 2/20\n",
      "180040/180040 [==============================] - 2068s 11ms/step - loss: 1.1654 - acc: 0.5057 - val_loss: 1.0923 - val_acc: 0.5314\n",
      "Epoch 3/20\n",
      "180040/180040 [==============================] - 2006s 11ms/step - loss: 1.1117 - acc: 0.5376 - val_loss: 1.0264 - val_acc: 0.5797\n",
      "Epoch 4/20\n",
      "180040/180040 [==============================] - 1935s 11ms/step - loss: 1.0651 - acc: 0.5670 - val_loss: 0.9733 - val_acc: 0.6093\n",
      "Epoch 5/20\n",
      "180040/180040 [==============================] - 1928s 11ms/step - loss: 1.0252 - acc: 0.5924 - val_loss: 0.9341 - val_acc: 0.6332\n",
      "Epoch 6/20\n",
      "180040/180040 [==============================] - 1919s 11ms/step - loss: 0.9898 - acc: 0.6113 - val_loss: 0.9203 - val_acc: 0.6395\n",
      "Epoch 7/20\n",
      "180040/180040 [==============================] - 1881s 10ms/step - loss: 0.9642 - acc: 0.6254 - val_loss: 0.8918 - val_acc: 0.6507\n",
      "Epoch 8/20\n",
      "180040/180040 [==============================] - 1605s 9ms/step - loss: 0.9382 - acc: 0.6381 - val_loss: 0.8867 - val_acc: 0.6575\n",
      "Epoch 9/20\n",
      "180040/180040 [==============================] - 1849s 10ms/step - loss: 0.9161 - acc: 0.6481 - val_loss: 0.8692 - val_acc: 0.6610\n",
      "Epoch 10/20\n",
      "180040/180040 [==============================] - 2017s 11ms/step - loss: 0.8985 - acc: 0.6553 - val_loss: 0.8661 - val_acc: 0.6655\n",
      "Epoch 11/20\n",
      "180040/180040 [==============================] - 1689s 9ms/step - loss: 0.8786 - acc: 0.6638 - val_loss: 0.8639 - val_acc: 0.6690\n",
      "Epoch 12/20\n",
      "180040/180040 [==============================] - 1724s 10ms/step - loss: 0.8588 - acc: 0.6702 - val_loss: 0.8675 - val_acc: 0.6706\n",
      "CPU times: user 19h 51min 41s, sys: 2h 30min 11s, total: 22h 21min 53s\n",
      "Wall time: 6h 18min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Bidirectional, LSTM, Flatten, Dropout, Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "WINDOW = 5   # number of tokens in one timestep\n",
    "TIMESTEP = EMBEDDING_DIM * WINDOW\n",
    "TIME_LENGTH = int(MAX_SEQ_LEN / WINDOW)\n",
    "\n",
    "# reshape input \n",
    "X_seq_input = X_token_seq_all_v.reshape(X_token_seq_all_v.shape[0], TIMESTEP, TIME_LENGTH)\n",
    "\n",
    "print(X_seq_input.shape)\n",
    "\n",
    "sequence_input = Input(shape=(TIMESTEP, TIME_LENGTH), dtype='float32')\n",
    "lstm = LSTM(units=TIMESTEP * 5, return_sequences=False)(sequence_input)\n",
    "D1 = Dense(100, activation='relu', name='sentence_vector_1')(lstm)\n",
    "D1 = Dropout(0.5)(D1)\n",
    "D1 = Dense(20, activation='relu', name='sentence_vector_2')(D1)\n",
    "D1 = Dropout(0.5)(D1)\n",
    "preds = Dense(len(label_dict), activation='softmax')(D1)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# learn\n",
    "model.fit(X_seq_input[:X_train_cnt], y_all[:X_train_cnt], \\\n",
    "          validation_data=(X_seq_input[X_train_cnt:(X_train_cnt+X_valid_cnt)], \\\n",
    "                                 y_all[X_train_cnt:(X_train_cnt+X_valid_cnt)]), \\\n",
    "          callbacks=[EarlyStopping(patience=1, monitor='val_loss')], \\\n",
    "          verbose=1, epochs=20, batch_size=256)\n",
    "\n",
    "model3 = model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model1.save('input/Extension_Part1_LSTM_MLP_POS_TAG1.h5')\n",
    "model2.save('input/Extension_Part1_LSTM_MLP_POS_TAG2.h5')\n",
    "model3.save('input/Extension_Part1_LSTM_MLP_POS_TAG3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
