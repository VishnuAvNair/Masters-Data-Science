{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONV1 with Constituent Tree Parse (part 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>partition</th>\n",
       "      <th>abstract_id</th>\n",
       "      <th>seq</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>deptree</th>\n",
       "      <th>deptree2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>4293578</td>\n",
       "      <td>0</td>\n",
       "      <td>To investigate the efficacy of 6 weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at 12 weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .</td>\n",
       "      <td>OBJECTIVE</td>\n",
       "      <td>( ROOT ( S ( S ( VP ( TO ) ( VP ( VB ) ( NP ( NP ( DT ) ( NN ) ) ( PP ( IN ) ( NP ( NP ( CD ) ( NNS ) ) ( PP ( IN ) ( NP ( JJ ) ( JJ ) ( JJ ) ( NN ) ) ) ) ) ) ( PP ( IN ) ( S ( VP ( VBG ) ( NP ( NP ( NN ) ) ( , ) ( NP ( NN ) ) ( , ) ( CC ) ( NP ( NP ( JJ ) ( JJ ) ( NN ) ) ( PP ( IN ) ( NP ( DT ) ( JJ ) ( NN ) ) ) ) ) ) ) ) ) ) ) ( CC ) ( S ( NP ( IN ) ( DT ) ( NN ) ) ( VP ( MD ) ( VP ( VB ) ( VP ( VBN ) ( PP ( IN ) ( NP ( NP ( CD ) ( NNS ) ) ( PP ( IN ) ( NP ( NP ( JJR ) ( NNS ) ) ( PP ( IN ...</td>\n",
       "      <td>( ROOT ( S ( S ( VP ( TO ) ( VP ( VB ) ( NP ( NP ( DT ) ( NN ) ) ( PP ( IN ) ( NP ( NP ( CD ) ( NNS ) ) ( PP ( IN ) ( NP ( JJ ) ( JJ ) ( JJ ) ( NN ) ) ) ) ) ) ( PP ( IN ) ( S ( VP ( VBG ) ( NP ( NP ( NN ) ) ( , ) ( NP ( NN ) ) ( , ) ( CC ) ( NP ( NP ( JJ ) ( JJ ) ( NN ) ) ( PP ( IN ) ( NP ( DT ) ( JJ ) ( NN ) ) ) ) ) ) ) ) ) ) ) ( CC ) ( S ( NP ( IN ) ( DT ) ( NN ) ) ( VP ( MD ) ( VP ( VB ) ( VP ( VBN ) ( PP ( IN ) ( NP ( NP ( CD ) ( NNS ) ) ( PP ( IN ) ( NP ( NP ( JJR ) ( NNS ) ) ( PP ( IN ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train</td>\n",
       "      <td>4293578</td>\n",
       "      <td>1</td>\n",
       "      <td>A total of 125 patients with primary knee OA were randomized 1:1 ; 63 received 7.5 mg/day of prednisolone and 62 received placebo for 6 weeks .</td>\n",
       "      <td>METHODS</td>\n",
       "      <td>( ROOT ( S ( S ( NP ( NP ( DT ) ( NN ) ) ( PP ( IN ) ( NP ( NP ( CD ) ( NNS ) ) ( PP ( IN ) ( NP ( JJ ) ( NN ) ( NN ) ) ) ) ) ) ( VP ( VBD ) ( VP ( VBN ) ( NP ( CD ) ) ) ) ) ( : ) ( S ( NP ( CD ) ) ( VP ( VBD ) ( SBAR ( S ( NP ( NP ( CD ) ( NN mg/day ) ) ( PP ( IN ) ( NP ( NP ( NN ) ) ( CC ) ( NP ( CD ) ) ) ) ) ( VP ( VBD ) ( NP ( NN ) ) ( PP ( IN ) ( NP ( CD ) ( NNS ) ) ) ) ) ) ) ) ( . ) ) )</td>\n",
       "      <td>( ROOT ( S ( S ( NP ( NP ( DT ) ( NN ) ) ( PP ( IN ) ( NP ( NP ( CD ) ( NNS ) ) ( PP ( IN ) ( NP ( JJ ) ( NN ) ( NN ) ) ) ) ) ) ( VP ( VBD ) ( VP ( VBN ) ( NP ( CD ) ) ) ) ) ( ( S ( NP ( CD ) ) ( VP ( VBD ) ( SBAR ( S ( NP ( NP ( CD ) ( NN ) ( PP ( IN ) ( NP ( NP ( NN ) ) ( CC ) ( NP ( CD ) ) ) ) ) ( VP ( VBD ) ( NP ( NN ) ) ( PP ( IN ) ( NP ( CD ) ( NNS ) ) ) ) ) ) ) ) ( . ) ) )</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train</td>\n",
       "      <td>4293578</td>\n",
       "      <td>2</td>\n",
       "      <td>Outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .</td>\n",
       "      <td>METHODS</td>\n",
       "      <td>( ROOT ( S ( NP ( NN ) ( NNS ) ) ( VP ( VBD ) ( NP ( NN ) ( NN ) ( CC ) ( NN ) ) ( PP ( IN ) ( NP ( NP ( NN ) ( NNS ) ) ( CC ) ( NP ( JJ ) ( NN ) ( NNS ) ) ) ) ) ( . ) ) )</td>\n",
       "      <td>( ROOT ( S ( NP ( NN ) ( NNS ) ) ( VP ( VBD ) ( NP ( NN ) ( NN ) ( CC ) ( NN ) ) ( PP ( IN ) ( NP ( NP ( NN ) ( NNS ) ) ( CC ) ( NP ( JJ ) ( NN ) ( NNS ) ) ) ) ) ( . ) ) )</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train</td>\n",
       "      <td>4293578</td>\n",
       "      <td>3</td>\n",
       "      <td>Pain was assessed using the visual analog pain scale ( 0-100 mm ) .</td>\n",
       "      <td>METHODS</td>\n",
       "      <td>( ROOT ( S ( NP ( NN ) ) ( VP ( VBD ) ( VP ( VBN ) ( S ( VP ( VBG ) ( NP ( NP ( DT ) ( JJ ) ( NN ) ( NN ) ( NN ) ) ( PRN ( -LRB- ) ( NP ( CD ) ( NN ) ) ( -RRB- ) ) ) ) ) ) ) ( . ) ) )</td>\n",
       "      <td>( ROOT ( S ( NP ( NN ) ) ( VP ( VBD ) ( VP ( VBN ) ( S ( VP ( VBG ) ( NP ( NP ( DT ) ( JJ ) ( NN ) ( NN ) ( NN ) ) ( PRN ( LRB ) ( NP ( CD ) ( NN ) ) ( RRB ) ) ) ) ) ) ) ( . ) ) )</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train</td>\n",
       "      <td>4293578</td>\n",
       "      <td>4</td>\n",
       "      <td>Secondary outcome measures included the Western Ontario and McMaster Universities Osteoarthritis Index scores , patient global assessment ( PGA ) of the severity of knee OA , and 6-min walk distance ( 6MWD ) .</td>\n",
       "      <td>METHODS</td>\n",
       "      <td>( ROOT ( S ( NP ( JJ ) ( NN ) ( NNS ) ) ( VP ( VBD ) ( NP ( NP ( NP ( DT ) ( JJ ) ( NNP ) ( CC ) ( NNP ) ( NNS ) ) ( NP ( NNP ) ( NNP ) ( NNS ) ) ) ( , ) ( NP ( NP ( NP ( NN ) ( JJ ) ( NN ) ) ( PRN ( -LRB- ) ( NP ( NN ) ) ( -RRB- ) ) ) ( PP ( IN ) ( NP ( NP ( DT ) ( NN ) ) ( PP ( IN ) ( NP ( NN ) ( NN ) ) ) ) ) ) ( , ) ( CC ) ( NP ( NP ( JJ ) ( NN ) ( NN ) ) ( PRN ( -LRB- ) ( NP ( NN ) ) ( -RRB- ) ) ) ) ) ( . ) ) )</td>\n",
       "      <td>( ROOT ( S ( NP ( JJ ) ( NN ) ( NNS ) ) ( VP ( VBD ) ( NP ( NP ( NP ( DT ) ( JJ ) ( NNP ) ( CC ) ( NNP ) ( NNS ) ) ( NP ( NNP ) ( NNP ) ( NNS ) ) ) ( , ) ( NP ( NP ( NP ( NN ) ( JJ ) ( NN ) ) ( PRN ( LRB ) ( NP ( NN ) ) ( RRB ) ) ) ( PP ( IN ) ( NP ( NP ( DT ) ( NN ) ) ( PP ( IN ) ( NP ( NN ) ( NN ) ) ) ) ) ) ( , ) ( CC ) ( NP ( NP ( JJ ) ( NN ) ( NN ) ) ( PRN ( LRB ) ( NP ( NN ) ) ( RRB ) ) ) ) ) ( . ) ) )</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  partition  abstract_id  seq  \\\n",
       "0     train      4293578    0   \n",
       "1     train      4293578    1   \n",
       "2     train      4293578    2   \n",
       "3     train      4293578    3   \n",
       "4     train      4293578    4   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                         text  \\\n",
       "0  To investigate the efficacy of 6 weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at 12 weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .   \n",
       "1                                                                                                                                             A total of 125 patients with primary knee OA were randomized 1:1 ; 63 received 7.5 mg/day of prednisolone and 62 received placebo for 6 weeks .   \n",
       "2                                                                                                                                                                             Outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .   \n",
       "3                                                                                                                                                                                                                         Pain was assessed using the visual analog pain scale ( 0-100 mm ) .   \n",
       "4                                                                           Secondary outcome measures included the Western Ontario and McMaster Universities Osteoarthritis Index scores , patient global assessment ( PGA ) of the severity of knee OA , and 6-min walk distance ( 6MWD ) .   \n",
       "\n",
       "       label  \\\n",
       "0  OBJECTIVE   \n",
       "1    METHODS   \n",
       "2    METHODS   \n",
       "3    METHODS   \n",
       "4    METHODS   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               deptree  \\\n",
       "0  ( ROOT ( S ( S ( VP ( TO ) ( VP ( VB ) ( NP ( NP ( DT ) ( NN ) ) ( PP ( IN ) ( NP ( NP ( CD ) ( NNS ) ) ( PP ( IN ) ( NP ( JJ ) ( JJ ) ( JJ ) ( NN ) ) ) ) ) ) ( PP ( IN ) ( S ( VP ( VBG ) ( NP ( NP ( NN ) ) ( , ) ( NP ( NN ) ) ( , ) ( CC ) ( NP ( NP ( JJ ) ( JJ ) ( NN ) ) ( PP ( IN ) ( NP ( DT ) ( JJ ) ( NN ) ) ) ) ) ) ) ) ) ) ) ( CC ) ( S ( NP ( IN ) ( DT ) ( NN ) ) ( VP ( MD ) ( VP ( VB ) ( VP ( VBN ) ( PP ( IN ) ( NP ( NP ( CD ) ( NNS ) ) ( PP ( IN ) ( NP ( NP ( JJR ) ( NNS ) ) ( PP ( IN ...   \n",
       "1                                                                                                          ( ROOT ( S ( S ( NP ( NP ( DT ) ( NN ) ) ( PP ( IN ) ( NP ( NP ( CD ) ( NNS ) ) ( PP ( IN ) ( NP ( JJ ) ( NN ) ( NN ) ) ) ) ) ) ( VP ( VBD ) ( VP ( VBN ) ( NP ( CD ) ) ) ) ) ( : ) ( S ( NP ( CD ) ) ( VP ( VBD ) ( SBAR ( S ( NP ( NP ( CD ) ( NN mg/day ) ) ( PP ( IN ) ( NP ( NP ( NN ) ) ( CC ) ( NP ( CD ) ) ) ) ) ( VP ( VBD ) ( NP ( NN ) ) ( PP ( IN ) ( NP ( CD ) ( NNS ) ) ) ) ) ) ) ) ( . ) ) )   \n",
       "2                                                                                                                                                                                                                                                                                                                                          ( ROOT ( S ( NP ( NN ) ( NNS ) ) ( VP ( VBD ) ( NP ( NN ) ( NN ) ( CC ) ( NN ) ) ( PP ( IN ) ( NP ( NP ( NN ) ( NNS ) ) ( CC ) ( NP ( JJ ) ( NN ) ( NNS ) ) ) ) ) ( . ) ) )   \n",
       "3                                                                                                                                                                                                                                                                                                                              ( ROOT ( S ( NP ( NN ) ) ( VP ( VBD ) ( VP ( VBN ) ( S ( VP ( VBG ) ( NP ( NP ( DT ) ( JJ ) ( NN ) ( NN ) ( NN ) ) ( PRN ( -LRB- ) ( NP ( CD ) ( NN ) ) ( -RRB- ) ) ) ) ) ) ) ( . ) ) )   \n",
       "4                                                                                   ( ROOT ( S ( NP ( JJ ) ( NN ) ( NNS ) ) ( VP ( VBD ) ( NP ( NP ( NP ( DT ) ( JJ ) ( NNP ) ( CC ) ( NNP ) ( NNS ) ) ( NP ( NNP ) ( NNP ) ( NNS ) ) ) ( , ) ( NP ( NP ( NP ( NN ) ( JJ ) ( NN ) ) ( PRN ( -LRB- ) ( NP ( NN ) ) ( -RRB- ) ) ) ( PP ( IN ) ( NP ( NP ( DT ) ( NN ) ) ( PP ( IN ) ( NP ( NN ) ( NN ) ) ) ) ) ) ( , ) ( CC ) ( NP ( NP ( JJ ) ( NN ) ( NN ) ) ( PRN ( -LRB- ) ( NP ( NN ) ) ( -RRB- ) ) ) ) ) ( . ) ) )   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              deptree2  \n",
       "0  ( ROOT ( S ( S ( VP ( TO ) ( VP ( VB ) ( NP ( NP ( DT ) ( NN ) ) ( PP ( IN ) ( NP ( NP ( CD ) ( NNS ) ) ( PP ( IN ) ( NP ( JJ ) ( JJ ) ( JJ ) ( NN ) ) ) ) ) ) ( PP ( IN ) ( S ( VP ( VBG ) ( NP ( NP ( NN ) ) ( , ) ( NP ( NN ) ) ( , ) ( CC ) ( NP ( NP ( JJ ) ( JJ ) ( NN ) ) ( PP ( IN ) ( NP ( DT ) ( JJ ) ( NN ) ) ) ) ) ) ) ) ) ) ) ( CC ) ( S ( NP ( IN ) ( DT ) ( NN ) ) ( VP ( MD ) ( VP ( VB ) ( VP ( VBN ) ( PP ( IN ) ( NP ( NP ( CD ) ( NNS ) ) ( PP ( IN ) ( NP ( NP ( JJR ) ( NNS ) ) ( PP ( IN ...  \n",
       "1                                                                                                                       ( ROOT ( S ( S ( NP ( NP ( DT ) ( NN ) ) ( PP ( IN ) ( NP ( NP ( CD ) ( NNS ) ) ( PP ( IN ) ( NP ( JJ ) ( NN ) ( NN ) ) ) ) ) ) ( VP ( VBD ) ( VP ( VBN ) ( NP ( CD ) ) ) ) ) ( ( S ( NP ( CD ) ) ( VP ( VBD ) ( SBAR ( S ( NP ( NP ( CD ) ( NN ) ( PP ( IN ) ( NP ( NP ( NN ) ) ( CC ) ( NP ( CD ) ) ) ) ) ( VP ( VBD ) ( NP ( NN ) ) ( PP ( IN ) ( NP ( CD ) ( NNS ) ) ) ) ) ) ) ) ( . ) ) )  \n",
       "2                                                                                                                                                                                                                                                                                                                                          ( ROOT ( S ( NP ( NN ) ( NNS ) ) ( VP ( VBD ) ( NP ( NN ) ( NN ) ( CC ) ( NN ) ) ( PP ( IN ) ( NP ( NP ( NN ) ( NNS ) ) ( CC ) ( NP ( JJ ) ( NN ) ( NNS ) ) ) ) ) ( . ) ) )  \n",
       "3                                                                                                                                                                                                                                                                                                                                  ( ROOT ( S ( NP ( NN ) ) ( VP ( VBD ) ( VP ( VBN ) ( S ( VP ( VBG ) ( NP ( NP ( DT ) ( JJ ) ( NN ) ( NN ) ( NN ) ) ( PRN ( LRB ) ( NP ( CD ) ( NN ) ) ( RRB ) ) ) ) ) ) ) ( . ) ) )  \n",
       "4                                                                                           ( ROOT ( S ( NP ( JJ ) ( NN ) ( NNS ) ) ( VP ( VBD ) ( NP ( NP ( NP ( DT ) ( JJ ) ( NNP ) ( CC ) ( NNP ) ( NNS ) ) ( NP ( NNP ) ( NNP ) ( NNS ) ) ) ( , ) ( NP ( NP ( NP ( NN ) ( JJ ) ( NN ) ) ( PRN ( LRB ) ( NP ( NN ) ) ( RRB ) ) ) ( PP ( IN ) ( NP ( NP ( DT ) ( NN ) ) ( PP ( IN ) ( NP ( NN ) ( NN ) ) ) ) ) ) ( , ) ( CC ) ( NP ( NP ( JJ ) ( NN ) ( NN ) ) ( PRN ( LRB ) ( NP ( NN ) ) ( RRB ) ) ) ) ) ( . ) ) )  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# file PubMed_20k_RCT.csv created by script01_create_single_dataset\n",
    "df_all = pd.read_csv('input/PubMed_20k_RCT_CONSTPARSE.csv')\n",
    "df_train = df_all[df_all['partition']=='train']\n",
    "df_valid = df_all[df_all['partition']=='dev']\n",
    "df_test = df_all[df_all['partition']=='test']\n",
    "pd.set_option('max_colwidth',500)\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train partition size: 180040\n",
      "Valid partition size: 30212\n",
      "Test partition size: 30135\n",
      "Total dataset size: 240387\n"
     ]
    }
   ],
   "source": [
    "X_train_cnt = df_train.shape[0]\n",
    "X_valid_cnt = df_valid.shape[0]\n",
    "X_test_cnt = df_test.shape[0]\n",
    "\n",
    "X_all = df_all.deptree2.values\n",
    "\n",
    "print('Train partition size: {}'.format(X_train_cnt))\n",
    "print('Valid partition size: {}'.format(X_valid_cnt))\n",
    "print('Test partition size: {}'.format(X_test_cnt))\n",
    "print('Total dataset size: {}'.format(X_all.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create token sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size = 50\n",
      "CPU times: user 4.8 s, sys: 765 ms, total: 5.56 s\n",
      "Wall time: 5.56 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# will only use 50 most common tokens\n",
    "\n",
    "all_text = ' '.join(X_all)\n",
    "all_tokens = [token for token in all_text.split()]\n",
    "top_tokens = Counter(all_tokens).most_common(50)\n",
    "i = 0\n",
    "word_index = {k:i+1 for i, (k, _) in enumerate(top_tokens)}\n",
    "\n",
    "VOC_SIZE = len(word_index)\n",
    "print('Vocabulary size = {}'.format(VOC_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = [[word_index[token] for token in parsetree.split() if word_index.get(token,-1)!=-1] for parsetree in X_all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3cAAAD8CAYAAADUrF2QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1834ef76d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seq_len = [len(seq) for seq in sequences]\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 4))\n",
    "axes[0].boxplot(seq_len)\n",
    "axes[1].hist(seq_len, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240387, 300)\n"
     ]
    }
   ],
   "source": [
    "MAX_SEQ_LEN = 300\n",
    "X_token_seq_all = pad_sequences(sequences, maxlen=MAX_SEQ_LEN, dtype='int32', padding='pre', truncating='post', value=0)\n",
    "print(X_token_seq_all.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize output labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.99 s, sys: 62.7 ms, total: 2.06 s\n",
      "Wall time: 2.08 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "labels = df_all.label.values\n",
    "label_dict = {label: no for no, label in enumerate(set(labels))}\n",
    "number_of_classes = len(label_dict)\n",
    "\n",
    "# get labels as integers\n",
    "y_all = [label_dict[label] for label in labels]\n",
    "\n",
    "# change y to categorical (vectorize output)\n",
    "y_all = np.array([to_categorical(i, num_classes=number_of_classes) for i in y_all])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Onehot encode Parse Tree labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240387, 300)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 2, 2, 2],\n",
       "       [0, 0, 0, ..., 2, 2, 2],\n",
       "       [0, 0, 0, ..., 2, 2, 2],\n",
       "       ..., \n",
       "       [0, 0, 0, ..., 2, 2, 2],\n",
       "       [0, 0, 0, ..., 2, 2, 2],\n",
       "       [0, 0, 0, ..., 2, 2, 2]], dtype=int32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_token_seq_all.shape)\n",
    "X_token_seq_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240387, 15000)\n",
      "(240387, 15000)\n",
      "CPU times: user 5min 53s, sys: 14 s, total: 6min 7s\n",
      "Wall time: 6min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "EMBEDDING_DIM = VOC_SIZE\n",
    "\n",
    "def get_vector(token):\n",
    "    vector = np.zeros(EMBEDDING_DIM)\n",
    "    if token != 0:\n",
    "        vector[token-1] = 1\n",
    "    return vector\n",
    "\n",
    "X_token_seq_all_v = np.zeros((X_token_seq_all.shape[0], X_token_seq_all.shape[1] * EMBEDDING_DIM))\n",
    "print(X_token_seq_all_v.shape)\n",
    "i = 0\n",
    "for token_seq in X_token_seq_all:\n",
    "    X_token_seq_all_v[i] = np.array([get_vector(token) for token in token_seq]).flatten()\n",
    "    i += 1\n",
    "    \n",
    "print(X_token_seq_all_v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240387, 300, 50)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 300, 50)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 296, 64)           16064     \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 292, 64)           20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 58, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 54, 128)           41088     \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 50, 128)           82048     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_3 ( (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "sentence_vector_1 (Dense)    (None, 100)               12900     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 505       \n",
      "=================================================================\n",
      "Total params: 173,149\n",
      "Trainable params: 173,149\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 180040 samples, validate on 30212 samples\n",
      "Epoch 1/20\n",
      "180040/180040 [==============================] - 425s 2ms/step - loss: 1.0372 - acc: 0.5571 - val_loss: 0.8015 - val_acc: 0.6743\n",
      "Epoch 2/20\n",
      "180040/180040 [==============================] - 403s 2ms/step - loss: 0.8061 - acc: 0.6878 - val_loss: 0.7183 - val_acc: 0.7196\n",
      "Epoch 3/20\n",
      "180040/180040 [==============================] - 400s 2ms/step - loss: 0.7479 - acc: 0.7154 - val_loss: 0.6770 - val_acc: 0.7369\n",
      "Epoch 4/20\n",
      "180040/180040 [==============================] - 6401s 36ms/step - loss: 0.7126 - acc: 0.7330 - val_loss: 0.6541 - val_acc: 0.7495\n",
      "Epoch 5/20\n",
      "180040/180040 [==============================] - 430s 2ms/step - loss: 0.6916 - acc: 0.7418 - val_loss: 0.6502 - val_acc: 0.7521\n",
      "Epoch 6/20\n",
      "180040/180040 [==============================] - 437s 2ms/step - loss: 0.6752 - acc: 0.7483 - val_loss: 0.6301 - val_acc: 0.7608\n",
      "Epoch 7/20\n",
      "180040/180040 [==============================] - 464s 3ms/step - loss: 0.6633 - acc: 0.7531 - val_loss: 0.6290 - val_acc: 0.7606\n",
      "Epoch 8/20\n",
      "180040/180040 [==============================] - 461s 3ms/step - loss: 0.6525 - acc: 0.7575 - val_loss: 0.6285 - val_acc: 0.7600\n",
      "Epoch 9/20\n",
      "180040/180040 [==============================] - 512s 3ms/step - loss: 0.6413 - acc: 0.7619 - val_loss: 0.6277 - val_acc: 0.7642\n",
      "Epoch 10/20\n",
      "180040/180040 [==============================] - 722s 4ms/step - loss: 0.6338 - acc: 0.7653 - val_loss: 0.6175 - val_acc: 0.7665\n",
      "Epoch 11/20\n",
      "180040/180040 [==============================] - 596s 3ms/step - loss: 0.6239 - acc: 0.7689 - val_loss: 0.6170 - val_acc: 0.7667\n",
      "Epoch 12/20\n",
      "180040/180040 [==============================] - 774s 4ms/step - loss: 0.6170 - acc: 0.7720 - val_loss: 0.6245 - val_acc: 0.7631\n",
      "CPU times: user 6h 33min 17s, sys: 56min 1s, total: 7h 29min 18s\n",
      "Wall time: 3h 20min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# implementing 1D convolution ann as decribed in Keras tutorial\n",
    "# https://keras.io/getting-started/sequential-model-guide/\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv1D, Input, Flatten, Dropout, Dense, MaxPooling1D, GlobalAveragePooling1D\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# reshape input to apply convolution\n",
    "KERNEL_SIZE = 5\n",
    "\n",
    "X_seq_input = X_token_seq_all_v.reshape(X_token_seq_all_v.shape[0], MAX_SEQ_LEN, EMBEDDING_DIM)\n",
    "print(X_seq_input.shape)\n",
    "\n",
    "postags = Input(shape=(MAX_SEQ_LEN, EMBEDDING_DIM), dtype='float32')\n",
    "C1 = Conv1D(64, KERNEL_SIZE, activation='relu')(postags)\n",
    "C1 = Conv1D(64, KERNEL_SIZE, activation='relu')(C1)\n",
    "C1 = MaxPooling1D(KERNEL_SIZE)(C1)\n",
    "C1 = Conv1D(128, KERNEL_SIZE, activation='relu')(C1)\n",
    "C1 = Conv1D(128, KERNEL_SIZE, activation='relu')(C1)\n",
    "C1 = GlobalAveragePooling1D()(C1)\n",
    "C1 = Dropout(0.5)(C1)\n",
    "C1 = Dense(100, activation='relu', name='sentence_vector_1')(C1)\n",
    "C1 = Dropout(0.5)(C1)\n",
    "preds = Dense(5, activation='softmax')(C1)\n",
    "\n",
    "model = Model(postags, preds)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# learn\n",
    "model.fit(X_seq_input[:X_train_cnt], y_all[:X_train_cnt], \\\n",
    "          validation_data=(X_seq_input[X_train_cnt:(X_train_cnt+X_valid_cnt)], \\\n",
    "                                 y_all[X_train_cnt:(X_train_cnt+X_valid_cnt)]), \\\n",
    "          callbacks=[EarlyStopping(patience=1, monitor='val_loss')], \\\n",
    "          verbose=1, epochs=20, batch_size=256)\n",
    "\n",
    "model1 = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 300, 50)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 296, 64)           16064     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 59, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 55, 128)           41088     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_6 ( (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "sentence_vector_1 (Dense)    (None, 100)               12900     \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 5)                 505       \n",
      "=================================================================\n",
      "Total params: 70,557\n",
      "Trainable params: 70,557\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 180040 samples, validate on 30212 samples\n",
      "Epoch 1/20\n",
      "180040/180040 [==============================] - 396s 2ms/step - loss: 1.0829 - acc: 0.5359 - val_loss: 0.8386 - val_acc: 0.6583\n",
      "Epoch 2/20\n",
      "180040/180040 [==============================] - 356s 2ms/step - loss: 0.8598 - acc: 0.6606 - val_loss: 0.7613 - val_acc: 0.7025\n",
      "Epoch 3/20\n",
      "180040/180040 [==============================] - 361s 2ms/step - loss: 0.8059 - acc: 0.6896 - val_loss: 0.7267 - val_acc: 0.7169\n",
      "Epoch 4/20\n",
      "180040/180040 [==============================] - 356s 2ms/step - loss: 0.7794 - acc: 0.7000 - val_loss: 0.7058 - val_acc: 0.7277\n",
      "Epoch 5/20\n",
      "180040/180040 [==============================] - 358s 2ms/step - loss: 0.7574 - acc: 0.7105 - val_loss: 0.6992 - val_acc: 0.7311\n",
      "Epoch 6/20\n",
      "180040/180040 [==============================] - 348s 2ms/step - loss: 0.7457 - acc: 0.7165 - val_loss: 0.6804 - val_acc: 0.7376\n",
      "Epoch 7/20\n",
      "180040/180040 [==============================] - 348s 2ms/step - loss: 0.7343 - acc: 0.7210 - val_loss: 0.6727 - val_acc: 0.7418\n",
      "Epoch 8/20\n",
      "180040/180040 [==============================] - 371s 2ms/step - loss: 0.7247 - acc: 0.7249 - val_loss: 0.6651 - val_acc: 0.7442\n",
      "Epoch 9/20\n",
      "180040/180040 [==============================] - 364s 2ms/step - loss: 0.7167 - acc: 0.7293 - val_loss: 0.6590 - val_acc: 0.7467\n",
      "Epoch 10/20\n",
      "180040/180040 [==============================] - 359s 2ms/step - loss: 0.7084 - acc: 0.7325 - val_loss: 0.6545 - val_acc: 0.7476\n",
      "Epoch 11/20\n",
      "180040/180040 [==============================] - 366s 2ms/step - loss: 0.7059 - acc: 0.7329 - val_loss: 0.6511 - val_acc: 0.7494\n",
      "Epoch 12/20\n",
      "180040/180040 [==============================] - 356s 2ms/step - loss: 0.6994 - acc: 0.7366 - val_loss: 0.6558 - val_acc: 0.7509\n",
      "CPU times: user 2h 55min 11s, sys: 28min 25s, total: 3h 23min 36s\n",
      "Wall time: 1h 12min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# implementing 1D convolution ann as decribed in Keras tutorial\n",
    "# https://keras.io/getting-started/sequential-model-guide/\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv1D, Input, Flatten, Dropout, Dense, MaxPooling1D, GlobalAveragePooling1D\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# reshape input to apply convolution\n",
    "KERNEL_SIZE = 5\n",
    "\n",
    "X_seq_input = X_token_seq_all_v.reshape(X_token_seq_all_v.shape[0], MAX_SEQ_LEN, EMBEDDING_DIM)\n",
    "\n",
    "postags = Input(shape=(MAX_SEQ_LEN, EMBEDDING_DIM), dtype='float32')\n",
    "C1 = Conv1D(64, KERNEL_SIZE, activation='relu')(postags)\n",
    "C1 = MaxPooling1D(KERNEL_SIZE)(C1)\n",
    "C1 = Conv1D(128, KERNEL_SIZE, activation='relu')(C1)\n",
    "C1 = GlobalAveragePooling1D()(C1)\n",
    "C1 = Dropout(0.5)(C1)\n",
    "C1 = Dense(100, activation='relu', name='sentence_vector_1')(C1)\n",
    "C1 = Dropout(0.5)(C1)\n",
    "preds = Dense(5, activation='softmax')(C1)\n",
    "\n",
    "model = Model(postags, preds)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# learn\n",
    "model.fit(X_seq_input[:X_train_cnt], y_all[:X_train_cnt], \\\n",
    "          validation_data=(X_seq_input[X_train_cnt:(X_train_cnt+X_valid_cnt)], \\\n",
    "                                 y_all[X_train_cnt:(X_train_cnt+X_valid_cnt)]), \\\n",
    "          callbacks=[EarlyStopping(patience=1, monitor='val_loss')], \\\n",
    "          verbose=1, epochs=20, batch_size=256)\n",
    "\n",
    "model2 = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        (None, 300, 50)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 291, 64)           32064     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 29, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_28 (Conv1D)           (None, 20, 128)           82048     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_9 ( (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "sentence_vector_1 (Dense)    (None, 100)               12900     \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 5)                 505       \n",
      "=================================================================\n",
      "Total params: 127,517\n",
      "Trainable params: 127,517\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 180040 samples, validate on 30212 samples\n",
      "Epoch 1/20\n",
      "180040/180040 [==============================] - 536s 3ms/step - loss: 1.0093 - acc: 0.5792 - val_loss: 0.7595 - val_acc: 0.7104\n",
      "Epoch 2/20\n",
      "180040/180040 [==============================] - 516s 3ms/step - loss: 0.7847 - acc: 0.7003 - val_loss: 0.7012 - val_acc: 0.7298\n",
      "Epoch 3/20\n",
      "180040/180040 [==============================] - 512s 3ms/step - loss: 0.7375 - acc: 0.7221 - val_loss: 0.6726 - val_acc: 0.7410\n",
      "Epoch 4/20\n",
      "180040/180040 [==============================] - 491s 3ms/step - loss: 0.7110 - acc: 0.7327 - val_loss: 0.6614 - val_acc: 0.7435\n",
      "Epoch 5/20\n",
      "180040/180040 [==============================] - 483s 3ms/step - loss: 0.6943 - acc: 0.7401 - val_loss: 0.6496 - val_acc: 0.7530\n",
      "Epoch 6/20\n",
      "180040/180040 [==============================] - 464s 3ms/step - loss: 0.6802 - acc: 0.7461 - val_loss: 0.6411 - val_acc: 0.7566\n",
      "Epoch 7/20\n",
      "180040/180040 [==============================] - 469s 3ms/step - loss: 0.6698 - acc: 0.7506 - val_loss: 0.6437 - val_acc: 0.7535\n",
      "CPU times: user 2h 22min 49s, sys: 24min 3s, total: 2h 46min 52s\n",
      "Wall time: 57min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# implementing 1D convolution ann as decribed in Keras tutorial\n",
    "# https://keras.io/getting-started/sequential-model-guide/\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv1D, Input, Flatten, Dropout, Dense, MaxPooling1D, GlobalAveragePooling1D\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# reshape input to apply convolution\n",
    "KERNEL_SIZE = 10\n",
    "\n",
    "X_seq_input = X_token_seq_all_v.reshape(X_token_seq_all_v.shape[0], MAX_SEQ_LEN, EMBEDDING_DIM)\n",
    "\n",
    "postags = Input(shape=(MAX_SEQ_LEN, EMBEDDING_DIM), dtype='float32')\n",
    "C1 = Conv1D(64, KERNEL_SIZE, activation='relu')(postags)\n",
    "C1 = MaxPooling1D(KERNEL_SIZE)(C1)\n",
    "C1 = Conv1D(128, KERNEL_SIZE, activation='relu')(C1)\n",
    "C1 = GlobalAveragePooling1D()(C1)\n",
    "C1 = Dropout(0.5)(C1)\n",
    "C1 = Dense(100, activation='relu', name='sentence_vector_1')(C1)\n",
    "C1 = Dropout(0.5)(C1)\n",
    "preds = Dense(5, activation='softmax')(C1)\n",
    "\n",
    "model = Model(postags, preds)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# learn\n",
    "model.fit(X_seq_input[:X_train_cnt], y_all[:X_train_cnt], \\\n",
    "          validation_data=(X_seq_input[X_train_cnt:(X_train_cnt+X_valid_cnt)], \\\n",
    "                                 y_all[X_train_cnt:(X_train_cnt+X_valid_cnt)]), \\\n",
    "          callbacks=[EarlyStopping(patience=1, monitor='val_loss')], \\\n",
    "          verbose=1, epochs=20, batch_size=256)\n",
    "\n",
    "model3 = model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model1.save('input/Extension_Part1_CONV1_CONSTPARSE1.h5')\n",
    "model2.save('input/Extension_Part1_CONV1_CONSTPARSE2.h5')\n",
    "model3.save('input/Extension_Part1_CONV1_CONSTPARSE3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
