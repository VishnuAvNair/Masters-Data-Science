{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bi-LSTM MLP with POS TAG (part 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>partition</th>\n",
       "      <th>abstract_id</th>\n",
       "      <th>seq</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>postaglist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>4293578</td>\n",
       "      <td>0</td>\n",
       "      <td>To investigate the efficacy of 6 weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at 12 weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .</td>\n",
       "      <td>OBJECTIVE</td>\n",
       "      <td>PART VERB DET NOUN ADP NUM NOUN ADP ADJ ADJ PUNCT NOUN ADJ NOUN ADP VERB NOUN PUNCT NOUN PUNCT CCONJ ADJ ADJ PUNCT NOUN NOUN ADP DET ADJ NOUN CCONJ ADP DET NOUN VERB VERB VERB ADP NUM NOUN ADP ADJ NOUN ADP ADJ ADP ADJ NOUN NOUN PUNCT PROPN PUNCT PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train</td>\n",
       "      <td>4293578</td>\n",
       "      <td>1</td>\n",
       "      <td>A total of 125 patients with primary knee OA were randomized 1:1 ; 63 received 7.5 mg/day of prednisolone and 62 received placebo for 6 weeks .</td>\n",
       "      <td>METHODS</td>\n",
       "      <td>DET NOUN ADP NUM NOUN ADP ADJ NOUN PROPN VERB VERB NUM PUNCT NUM VERB NUM NOUN SYM NOUN ADP NOUN CCONJ NUM VERB NOUN ADP NUM NOUN PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train</td>\n",
       "      <td>4293578</td>\n",
       "      <td>2</td>\n",
       "      <td>Outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .</td>\n",
       "      <td>METHODS</td>\n",
       "      <td>PROPN NOUN VERB NOUN NOUN CCONJ NOUN ADP NOUN NOUN CCONJ ADJ NOUN NOUN PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train</td>\n",
       "      <td>4293578</td>\n",
       "      <td>3</td>\n",
       "      <td>Pain was assessed using the visual analog pain scale ( 0-100 mm ) .</td>\n",
       "      <td>METHODS</td>\n",
       "      <td>PROPN VERB VERB VERB DET ADJ NOUN NOUN NOUN PUNCT NUM SYM NUM NOUN PUNCT PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train</td>\n",
       "      <td>4293578</td>\n",
       "      <td>4</td>\n",
       "      <td>Secondary outcome measures included the Western Ontario and McMaster Universities Osteoarthritis Index scores , patient global assessment ( PGA ) of the severity of knee OA , and 6-min walk distance ( 6MWD ) .</td>\n",
       "      <td>METHODS</td>\n",
       "      <td>ADJ NOUN NOUN VERB DET PROPN PROPN CCONJ PROPN PROPN PROPN PROPN NOUN PUNCT ADJ ADJ NOUN PUNCT PROPN PUNCT ADP DET NOUN ADP NOUN PROPN PUNCT CCONJ NUM NOUN NOUN PUNCT NOUN PUNCT PUNCT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  partition  abstract_id  seq  \\\n",
       "0     train      4293578    0   \n",
       "1     train      4293578    1   \n",
       "2     train      4293578    2   \n",
       "3     train      4293578    3   \n",
       "4     train      4293578    4   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                         text  \\\n",
       "0  To investigate the efficacy of 6 weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at 12 weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .   \n",
       "1                                                                                                                                             A total of 125 patients with primary knee OA were randomized 1:1 ; 63 received 7.5 mg/day of prednisolone and 62 received placebo for 6 weeks .   \n",
       "2                                                                                                                                                                             Outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .   \n",
       "3                                                                                                                                                                                                                         Pain was assessed using the visual analog pain scale ( 0-100 mm ) .   \n",
       "4                                                                           Secondary outcome measures included the Western Ontario and McMaster Universities Osteoarthritis Index scores , patient global assessment ( PGA ) of the severity of knee OA , and 6-min walk distance ( 6MWD ) .   \n",
       "\n",
       "       label  \\\n",
       "0  OBJECTIVE   \n",
       "1    METHODS   \n",
       "2    METHODS   \n",
       "3    METHODS   \n",
       "4    METHODS   \n",
       "\n",
       "                                                                                                                                                                                                                                                    postaglist  \n",
       "0  PART VERB DET NOUN ADP NUM NOUN ADP ADJ ADJ PUNCT NOUN ADJ NOUN ADP VERB NOUN PUNCT NOUN PUNCT CCONJ ADJ ADJ PUNCT NOUN NOUN ADP DET ADJ NOUN CCONJ ADP DET NOUN VERB VERB VERB ADP NUM NOUN ADP ADJ NOUN ADP ADJ ADP ADJ NOUN NOUN PUNCT PROPN PUNCT PUNCT  \n",
       "1                                                                                                                      DET NOUN ADP NUM NOUN ADP ADJ NOUN PROPN VERB VERB NUM PUNCT NUM VERB NUM NOUN SYM NOUN ADP NOUN CCONJ NUM VERB NOUN ADP NUM NOUN PUNCT  \n",
       "2                                                                                                                                                                                 PROPN NOUN VERB NOUN NOUN CCONJ NOUN ADP NOUN NOUN CCONJ ADJ NOUN NOUN PUNCT  \n",
       "3                                                                                                                                                                               PROPN VERB VERB VERB DET ADJ NOUN NOUN NOUN PUNCT NUM SYM NUM NOUN PUNCT PUNCT  \n",
       "4                                                                      ADJ NOUN NOUN VERB DET PROPN PROPN CCONJ PROPN PROPN PROPN PROPN NOUN PUNCT ADJ ADJ NOUN PUNCT PROPN PUNCT ADP DET NOUN ADP NOUN PROPN PUNCT CCONJ NUM NOUN NOUN PUNCT NOUN PUNCT PUNCT  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# file PubMed_20k_RCT.csv created by script01_create_single_dataset\n",
    "df_all = pd.read_csv('input/PubMed_20k_RCT_POS_TAG.csv')\n",
    "df_train = df_all[df_all['partition']=='train']\n",
    "df_valid = df_all[df_all['partition']=='dev']\n",
    "df_test = df_all[df_all['partition']=='test']\n",
    "pd.set_option('max_colwidth',500)\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train partition size: 180040\n",
      "Valid partition size: 30212\n",
      "Test partition size: 30135\n",
      "Total dataset size: 240387\n"
     ]
    }
   ],
   "source": [
    "X_train_cnt = df_train.shape[0]\n",
    "X_valid_cnt = df_valid.shape[0]\n",
    "X_test_cnt = df_test.shape[0]\n",
    "\n",
    "X_all = df_all.postaglist.values\n",
    "\n",
    "print('Train partition size: {}'.format(X_train_cnt))\n",
    "print('Valid partition size: {}'.format(X_valid_cnt))\n",
    "print('Test partition size: {}'.format(X_test_cnt))\n",
    "print('Total dataset size: {}'.format(X_all.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create token sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size = 15\n",
      "CPU times: user 10.2 s, sys: 74.4 ms, total: 10.3 s\n",
      "Wall time: 10.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# reduce vocabulary size to make problem manageable for available computing resources\n",
    "#SEQ_VOC = 50000\n",
    "#print('Number of tokens for sequences = {}'.format(SEQ_VOC))\n",
    "\n",
    "#tokenizer = Tokenizer(num_words=VOC_SIZE, filters='!\"*,./:;?@\\`|')\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_all)\n",
    "sequences = tokenizer.texts_to_sequences(X_all)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "VOC_SIZE = len(word_index)\n",
    "print('Vocabulary size = {}'.format(VOC_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adj': 5,\n",
       " 'adp': 3,\n",
       " 'adv': 10,\n",
       " 'cconj': 9,\n",
       " 'det': 7,\n",
       " 'intj': 15,\n",
       " 'noun': 1,\n",
       " 'num': 6,\n",
       " 'part': 12,\n",
       " 'pron': 14,\n",
       " 'propn': 8,\n",
       " 'punct': 2,\n",
       " 'sym': 11,\n",
       " 'verb': 4,\n",
       " 'x': 13}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3EAAAD8CAYAAADZsi3XAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114020fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seq_len = [len(seq) for seq in sequences]\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 4))\n",
    "axes[0].boxplot(seq_len)\n",
    "axes[1].hist(seq_len, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240387, 120)\n"
     ]
    }
   ],
   "source": [
    "MAX_SEQ_LEN = 120\n",
    "X_token_seq_all = pad_sequences(sequences, maxlen=MAX_SEQ_LEN, dtype='int32', padding='pre', truncating='post', value=0)\n",
    "print(X_token_seq_all.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize output labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.92 s, sys: 48.7 ms, total: 1.97 s\n",
      "Wall time: 1.97 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "labels = df_all.label.values\n",
    "label_dict = {label: no for no, label in enumerate(set(labels))}\n",
    "number_of_classes = len(label_dict)\n",
    "\n",
    "# get labels as integers\n",
    "y_all = [label_dict[label] for label in labels]\n",
    "\n",
    "# change y to categorical (vectorize output)\n",
    "y_all = np.array([to_categorical(i, num_classes=number_of_classes) for i in y_all])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240387, 120)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 8, 2, 2],\n",
       "       [0, 0, 0, ..., 6, 1, 2],\n",
       "       [0, 0, 0, ..., 1, 1, 2],\n",
       "       ..., \n",
       "       [0, 0, 0, ..., 1, 6, 2],\n",
       "       [0, 0, 0, ..., 4, 4, 2],\n",
       "       [0, 0, 0, ..., 8, 1, 2]], dtype=int32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_token_seq_all.shape)\n",
    "X_token_seq_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240387, 1800)\n",
      "(240387, 1800)\n",
      "CPU times: user 2min 11s, sys: 2.09 s, total: 2min 13s\n",
      "Wall time: 2min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "EMBEDDING_DIM = VOC_SIZE\n",
    "\n",
    "def get_vector(token):\n",
    "    vector = np.zeros(EMBEDDING_DIM)\n",
    "    if token != 0:\n",
    "        vector[token-1] = 1\n",
    "    return vector\n",
    "\n",
    "X_token_seq_all_v = np.zeros((X_token_seq_all.shape[0], X_token_seq_all.shape[1] * EMBEDDING_DIM))\n",
    "print(X_token_seq_all_v.shape)\n",
    "i = 0\n",
    "for token_seq in X_token_seq_all:\n",
    "    X_token_seq_all_v[i] = np.array([get_vector(token) for token in token_seq]).flatten()\n",
    "    i += 1\n",
    "    \n",
    "print(X_token_seq_all_v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240387, 15, 120)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 15, 120)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 150)               117600    \n",
      "_________________________________________________________________\n",
      "sentence_vector_1 (Dense)    (None, 100)               15100     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "sentence_vector_2 (Dense)    (None, 20)                2020      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 105       \n",
      "=================================================================\n",
      "Total params: 134,825\n",
      "Trainable params: 134,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 180040 samples, validate on 30212 samples\n",
      "Epoch 1/20\n",
      "180040/180040 [==============================] - 107s 592us/step - loss: 1.2063 - acc: 0.4883 - val_loss: 1.0288 - val_acc: 0.5892\n",
      "Epoch 2/20\n",
      "180040/180040 [==============================] - 105s 585us/step - loss: 1.0732 - acc: 0.5640 - val_loss: 0.9704 - val_acc: 0.6136\n",
      "Epoch 3/20\n",
      "180040/180040 [==============================] - 107s 592us/step - loss: 1.0258 - acc: 0.5904 - val_loss: 0.9350 - val_acc: 0.6289\n",
      "Epoch 4/20\n",
      "180040/180040 [==============================] - 105s 583us/step - loss: 0.9956 - acc: 0.6083 - val_loss: 0.9197 - val_acc: 0.6365\n",
      "Epoch 5/20\n",
      "180040/180040 [==============================] - 101s 561us/step - loss: 0.9720 - acc: 0.6210 - val_loss: 0.9072 - val_acc: 0.6386\n",
      "Epoch 6/20\n",
      "180040/180040 [==============================] - 100s 556us/step - loss: 0.9549 - acc: 0.6290 - val_loss: 0.8922 - val_acc: 0.6477\n",
      "Epoch 7/20\n",
      "180040/180040 [==============================] - 92s 512us/step - loss: 0.9396 - acc: 0.6387 - val_loss: 0.8795 - val_acc: 0.6555\n",
      "Epoch 8/20\n",
      "180040/180040 [==============================] - 96s 534us/step - loss: 0.9279 - acc: 0.6434 - val_loss: 0.8856 - val_acc: 0.6549\n",
      "CPU times: user 37min 16s, sys: 2min 25s, total: 39min 41s\n",
      "Wall time: 13min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Bidirectional, LSTM, Flatten, Dropout, Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "WINDOW = 1   # number of tokens in one timestep\n",
    "TIMESTEP = EMBEDDING_DIM * WINDOW\n",
    "TIME_LENGTH = int(MAX_SEQ_LEN / WINDOW)\n",
    "\n",
    "# reshape input \n",
    "X_seq_input = X_token_seq_all_v.reshape(X_token_seq_all_v.shape[0], TIMESTEP, TIME_LENGTH)\n",
    "\n",
    "print(X_seq_input.shape)\n",
    "\n",
    "sequence_input = Input(shape=(TIMESTEP, TIME_LENGTH), dtype='float32')\n",
    "lstm = Bidirectional(LSTM(units=TIMESTEP * 5, return_sequences=False))(sequence_input)\n",
    "D1 = Dense(100, activation='relu', name='sentence_vector_1')(lstm)\n",
    "D1 = Dropout(0.5)(D1)\n",
    "D1 = Dense(20, activation='relu', name='sentence_vector_2')(D1)\n",
    "D1 = Dropout(0.5)(D1)\n",
    "preds = Dense(len(label_dict), activation='softmax')(D1)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# learn\n",
    "model.fit(X_seq_input[:X_train_cnt], y_all[:X_train_cnt], \\\n",
    "          validation_data=(X_seq_input[X_train_cnt:(X_train_cnt+X_valid_cnt)], \\\n",
    "                                 y_all[X_train_cnt:(X_train_cnt+X_valid_cnt)]), \\\n",
    "          callbacks=[EarlyStopping(patience=1, monitor='val_loss')], \\\n",
    "          verbose=1, epochs=20, batch_size=256)\n",
    "\n",
    "model1 = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240387, 45, 40)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 45, 40)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 450)               478800    \n",
      "_________________________________________________________________\n",
      "sentence_vector_1 (Dense)    (None, 100)               45100     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "sentence_vector_2 (Dense)    (None, 20)                2020      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 105       \n",
      "=================================================================\n",
      "Total params: 526,025\n",
      "Trainable params: 526,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 180040 samples, validate on 30212 samples\n",
      "Epoch 1/20\n",
      "180040/180040 [==============================] - 1127s 6ms/step - loss: 1.2803 - acc: 0.4564 - val_loss: 1.1200 - val_acc: 0.5361\n",
      "Epoch 2/20\n",
      "180040/180040 [==============================] - 1106s 6ms/step - loss: 1.1180 - acc: 0.5432 - val_loss: 1.0084 - val_acc: 0.5977\n",
      "Epoch 3/20\n",
      "180040/180040 [==============================] - 1136s 6ms/step - loss: 1.0573 - acc: 0.5756 - val_loss: 0.9726 - val_acc: 0.6147\n",
      "Epoch 4/20\n",
      "180040/180040 [==============================] - 1275s 7ms/step - loss: 1.0203 - acc: 0.5944 - val_loss: 0.9305 - val_acc: 0.6331\n",
      "Epoch 5/20\n",
      "180040/180040 [==============================] - 967s 5ms/step - loss: 0.9950 - acc: 0.6098 - val_loss: 0.9233 - val_acc: 0.6318\n",
      "Epoch 6/20\n",
      "180040/180040 [==============================] - 966s 5ms/step - loss: 0.9711 - acc: 0.6207 - val_loss: 0.9060 - val_acc: 0.6426\n",
      "Epoch 7/20\n",
      "180040/180040 [==============================] - 967s 5ms/step - loss: 0.9532 - acc: 0.6297 - val_loss: 0.8956 - val_acc: 0.6458\n",
      "Epoch 8/20\n",
      "180040/180040 [==============================] - 950s 5ms/step - loss: 0.9337 - acc: 0.6386 - val_loss: 0.8763 - val_acc: 0.6592\n",
      "Epoch 9/20\n",
      "180040/180040 [==============================] - 952s 5ms/step - loss: 0.9203 - acc: 0.6460 - val_loss: 0.8721 - val_acc: 0.6615\n",
      "Epoch 10/20\n",
      "180040/180040 [==============================] - 945s 5ms/step - loss: 0.9053 - acc: 0.6519 - val_loss: 0.8597 - val_acc: 0.6677\n",
      "Epoch 11/20\n",
      "180040/180040 [==============================] - 950s 5ms/step - loss: 0.8878 - acc: 0.6594 - val_loss: 0.8584 - val_acc: 0.6682\n",
      "Epoch 12/20\n",
      "180040/180040 [==============================] - 948s 5ms/step - loss: 0.8737 - acc: 0.6649 - val_loss: 0.8546 - val_acc: 0.6718\n",
      "Epoch 13/20\n",
      "180040/180040 [==============================] - 945s 5ms/step - loss: 0.8571 - acc: 0.6721 - val_loss: 0.8740 - val_acc: 0.6712\n",
      "CPU times: user 11h 29min 3s, sys: 1h 50min 42s, total: 13h 19min 45s\n",
      "Wall time: 3h 40min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Bidirectional, LSTM, Flatten, Dropout, Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "WINDOW = 3   # number of tokens in one timestep\n",
    "TIMESTEP = EMBEDDING_DIM * WINDOW\n",
    "TIME_LENGTH = int(MAX_SEQ_LEN / WINDOW)\n",
    "\n",
    "# reshape input \n",
    "X_seq_input = X_token_seq_all_v.reshape(X_token_seq_all_v.shape[0], TIMESTEP, TIME_LENGTH)\n",
    "\n",
    "print(X_seq_input.shape)\n",
    "\n",
    "sequence_input = Input(shape=(TIMESTEP, TIME_LENGTH), dtype='float32')\n",
    "lstm = Bidirectional(LSTM(units=TIMESTEP * 5, return_sequences=False))(sequence_input)\n",
    "D1 = Dense(100, activation='relu', name='sentence_vector_1')(lstm)\n",
    "D1 = Dropout(0.5)(D1)\n",
    "D1 = Dense(20, activation='relu', name='sentence_vector_2')(D1)\n",
    "D1 = Dropout(0.5)(D1)\n",
    "preds = Dense(len(label_dict), activation='softmax')(D1)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# learn\n",
    "model.fit(X_seq_input[:X_train_cnt], y_all[:X_train_cnt], \\\n",
    "          validation_data=(X_seq_input[X_train_cnt:(X_train_cnt+X_valid_cnt)], \\\n",
    "                                 y_all[X_train_cnt:(X_train_cnt+X_valid_cnt)]), \\\n",
    "          callbacks=[EarlyStopping(patience=1, monitor='val_loss')], \\\n",
    "          verbose=1, epochs=20, batch_size=256)\n",
    "\n",
    "model2 = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240387, 75, 24)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 75, 24)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 750)               1200000   \n",
      "_________________________________________________________________\n",
      "sentence_vector_1 (Dense)    (None, 100)               75100     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "sentence_vector_2 (Dense)    (None, 20)                2020      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 105       \n",
      "=================================================================\n",
      "Total params: 1,277,225\n",
      "Trainable params: 1,277,225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 180040 samples, validate on 30212 samples\n",
      "Epoch 1/20\n",
      "180040/180040 [==============================] - 3644s 20ms/step - loss: 1.2770 - acc: 0.4452 - val_loss: 1.1512 - val_acc: 0.5036\n",
      "Epoch 2/20\n",
      "180040/180040 [==============================] - 3617s 20ms/step - loss: 1.1758 - acc: 0.4947 - val_loss: 1.1069 - val_acc: 0.5293\n",
      "Epoch 3/20\n",
      "180040/180040 [==============================] - 3143s 17ms/step - loss: 1.1345 - acc: 0.5179 - val_loss: 1.0640 - val_acc: 0.5588\n",
      "Epoch 4/20\n",
      "180040/180040 [==============================] - 3698s 21ms/step - loss: 1.0820 - acc: 0.5600 - val_loss: 0.9945 - val_acc: 0.6001\n",
      "Epoch 5/20\n",
      "180040/180040 [==============================] - 3199s 18ms/step - loss: 1.0324 - acc: 0.5894 - val_loss: 0.9366 - val_acc: 0.6289\n",
      "Epoch 6/20\n",
      "180040/180040 [==============================] - 1666s 9ms/step - loss: 0.9963 - acc: 0.6106 - val_loss: 0.9114 - val_acc: 0.6460\n",
      "Epoch 7/20\n",
      "180040/180040 [==============================] - 1638s 9ms/step - loss: 0.9667 - acc: 0.6251 - val_loss: 0.8980 - val_acc: 0.6503\n",
      "Epoch 8/20\n",
      "180040/180040 [==============================] - 1588s 9ms/step - loss: 0.9390 - acc: 0.6381 - val_loss: 0.8861 - val_acc: 0.6571\n",
      "Epoch 9/20\n",
      "180040/180040 [==============================] - 1604s 9ms/step - loss: 0.9207 - acc: 0.6470 - val_loss: 0.8756 - val_acc: 0.6599\n",
      "Epoch 10/20\n",
      "180040/180040 [==============================] - 1593s 9ms/step - loss: 0.8955 - acc: 0.6563 - val_loss: 0.8674 - val_acc: 0.6651\n",
      "Epoch 11/20\n",
      "180040/180040 [==============================] - 1625s 9ms/step - loss: 0.8757 - acc: 0.6669 - val_loss: 0.8652 - val_acc: 0.6653\n",
      "Epoch 12/20\n",
      "180040/180040 [==============================] - 1641s 9ms/step - loss: 0.8547 - acc: 0.6734 - val_loss: 0.8722 - val_acc: 0.6674\n",
      "CPU times: user 1d 12h 42min 36s, sys: 3h 55min 22s, total: 1d 16h 37min 58s\n",
      "Wall time: 7h 57min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Bidirectional, LSTM, Flatten, Dropout, Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "WINDOW = 5   # number of tokens in one timestep\n",
    "TIMESTEP = EMBEDDING_DIM * WINDOW\n",
    "TIME_LENGTH = int(MAX_SEQ_LEN / WINDOW)\n",
    "\n",
    "# reshape input \n",
    "X_seq_input = X_token_seq_all_v.reshape(X_token_seq_all_v.shape[0], TIMESTEP, TIME_LENGTH)\n",
    "\n",
    "print(X_seq_input.shape)\n",
    "\n",
    "sequence_input = Input(shape=(TIMESTEP, TIME_LENGTH), dtype='float32')\n",
    "lstm = Bidirectional(LSTM(units=TIMESTEP * 5, return_sequences=False))(sequence_input)\n",
    "D1 = Dense(100, activation='relu', name='sentence_vector_1')(lstm)\n",
    "D1 = Dropout(0.5)(D1)\n",
    "D1 = Dense(20, activation='relu', name='sentence_vector_2')(D1)\n",
    "D1 = Dropout(0.5)(D1)\n",
    "preds = Dense(len(label_dict), activation='softmax')(D1)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# learn\n",
    "model.fit(X_seq_input[:X_train_cnt], y_all[:X_train_cnt], \\\n",
    "          validation_data=(X_seq_input[X_train_cnt:(X_train_cnt+X_valid_cnt)], \\\n",
    "                                 y_all[X_train_cnt:(X_train_cnt+X_valid_cnt)]), \\\n",
    "          callbacks=[EarlyStopping(patience=1, monitor='val_loss')], \\\n",
    "          verbose=1, epochs=20, batch_size=256)\n",
    "\n",
    "model3 = model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model1.save('input/Extension_Part1_Bi-LSTM_MLP_POS_TAG1.h5')\n",
    "model2.save('input/Extension_Part1_Bi-LSTM_MLP_POS_TAG2.h5')\n",
    "model3.save('input/Extension_Part1_Bi-LSTM_MLP_POS_TAG3.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
