{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONV1 with POS TAG (part 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>partition</th>\n",
       "      <th>abstract_id</th>\n",
       "      <th>seq</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>postaglist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>4293578</td>\n",
       "      <td>0</td>\n",
       "      <td>To investigate the efficacy of 6 weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at 12 weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .</td>\n",
       "      <td>OBJECTIVE</td>\n",
       "      <td>PART VERB DET NOUN ADP NUM NOUN ADP ADJ ADJ PUNCT NOUN ADJ NOUN ADP VERB NOUN PUNCT NOUN PUNCT CCONJ ADJ ADJ PUNCT NOUN NOUN ADP DET ADJ NOUN CCONJ ADP DET NOUN VERB VERB VERB ADP NUM NOUN ADP ADJ NOUN ADP ADJ ADP ADJ NOUN NOUN PUNCT PROPN PUNCT PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train</td>\n",
       "      <td>4293578</td>\n",
       "      <td>1</td>\n",
       "      <td>A total of 125 patients with primary knee OA were randomized 1:1 ; 63 received 7.5 mg/day of prednisolone and 62 received placebo for 6 weeks .</td>\n",
       "      <td>METHODS</td>\n",
       "      <td>DET NOUN ADP NUM NOUN ADP ADJ NOUN PROPN VERB VERB NUM PUNCT NUM VERB NUM NOUN SYM NOUN ADP NOUN CCONJ NUM VERB NOUN ADP NUM NOUN PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train</td>\n",
       "      <td>4293578</td>\n",
       "      <td>2</td>\n",
       "      <td>Outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .</td>\n",
       "      <td>METHODS</td>\n",
       "      <td>PROPN NOUN VERB NOUN NOUN CCONJ NOUN ADP NOUN NOUN CCONJ ADJ NOUN NOUN PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train</td>\n",
       "      <td>4293578</td>\n",
       "      <td>3</td>\n",
       "      <td>Pain was assessed using the visual analog pain scale ( 0-100 mm ) .</td>\n",
       "      <td>METHODS</td>\n",
       "      <td>PROPN VERB VERB VERB DET ADJ NOUN NOUN NOUN PUNCT NUM SYM NUM NOUN PUNCT PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train</td>\n",
       "      <td>4293578</td>\n",
       "      <td>4</td>\n",
       "      <td>Secondary outcome measures included the Western Ontario and McMaster Universities Osteoarthritis Index scores , patient global assessment ( PGA ) of the severity of knee OA , and 6-min walk distance ( 6MWD ) .</td>\n",
       "      <td>METHODS</td>\n",
       "      <td>ADJ NOUN NOUN VERB DET PROPN PROPN CCONJ PROPN PROPN PROPN PROPN NOUN PUNCT ADJ ADJ NOUN PUNCT PROPN PUNCT ADP DET NOUN ADP NOUN PROPN PUNCT CCONJ NUM NOUN NOUN PUNCT NOUN PUNCT PUNCT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  partition  abstract_id  seq  \\\n",
       "0     train      4293578    0   \n",
       "1     train      4293578    1   \n",
       "2     train      4293578    2   \n",
       "3     train      4293578    3   \n",
       "4     train      4293578    4   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                         text  \\\n",
       "0  To investigate the efficacy of 6 weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at 12 weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .   \n",
       "1                                                                                                                                             A total of 125 patients with primary knee OA were randomized 1:1 ; 63 received 7.5 mg/day of prednisolone and 62 received placebo for 6 weeks .   \n",
       "2                                                                                                                                                                             Outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .   \n",
       "3                                                                                                                                                                                                                         Pain was assessed using the visual analog pain scale ( 0-100 mm ) .   \n",
       "4                                                                           Secondary outcome measures included the Western Ontario and McMaster Universities Osteoarthritis Index scores , patient global assessment ( PGA ) of the severity of knee OA , and 6-min walk distance ( 6MWD ) .   \n",
       "\n",
       "       label  \\\n",
       "0  OBJECTIVE   \n",
       "1    METHODS   \n",
       "2    METHODS   \n",
       "3    METHODS   \n",
       "4    METHODS   \n",
       "\n",
       "                                                                                                                                                                                                                                                    postaglist  \n",
       "0  PART VERB DET NOUN ADP NUM NOUN ADP ADJ ADJ PUNCT NOUN ADJ NOUN ADP VERB NOUN PUNCT NOUN PUNCT CCONJ ADJ ADJ PUNCT NOUN NOUN ADP DET ADJ NOUN CCONJ ADP DET NOUN VERB VERB VERB ADP NUM NOUN ADP ADJ NOUN ADP ADJ ADP ADJ NOUN NOUN PUNCT PROPN PUNCT PUNCT  \n",
       "1                                                                                                                      DET NOUN ADP NUM NOUN ADP ADJ NOUN PROPN VERB VERB NUM PUNCT NUM VERB NUM NOUN SYM NOUN ADP NOUN CCONJ NUM VERB NOUN ADP NUM NOUN PUNCT  \n",
       "2                                                                                                                                                                                 PROPN NOUN VERB NOUN NOUN CCONJ NOUN ADP NOUN NOUN CCONJ ADJ NOUN NOUN PUNCT  \n",
       "3                                                                                                                                                                               PROPN VERB VERB VERB DET ADJ NOUN NOUN NOUN PUNCT NUM SYM NUM NOUN PUNCT PUNCT  \n",
       "4                                                                      ADJ NOUN NOUN VERB DET PROPN PROPN CCONJ PROPN PROPN PROPN PROPN NOUN PUNCT ADJ ADJ NOUN PUNCT PROPN PUNCT ADP DET NOUN ADP NOUN PROPN PUNCT CCONJ NUM NOUN NOUN PUNCT NOUN PUNCT PUNCT  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# file PubMed_20k_RCT.csv created by script01_create_single_dataset\n",
    "df_all = pd.read_csv('input/PubMed_20k_RCT_POS_TAG.csv')\n",
    "df_train = df_all[df_all['partition']=='train']\n",
    "df_valid = df_all[df_all['partition']=='dev']\n",
    "df_test = df_all[df_all['partition']=='test']\n",
    "pd.set_option('max_colwidth',500)\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train partition size: 180040\n",
      "Valid partition size: 30212\n",
      "Test partition size: 30135\n",
      "Total dataset size: 240387\n"
     ]
    }
   ],
   "source": [
    "X_train_cnt = df_train.shape[0]\n",
    "X_valid_cnt = df_valid.shape[0]\n",
    "X_test_cnt = df_test.shape[0]\n",
    "\n",
    "X_all = df_all.postaglist.values\n",
    "\n",
    "print('Train partition size: {}'.format(X_train_cnt))\n",
    "print('Valid partition size: {}'.format(X_valid_cnt))\n",
    "print('Test partition size: {}'.format(X_test_cnt))\n",
    "print('Total dataset size: {}'.format(X_all.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create token sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size = 15\n",
      "CPU times: user 10 s, sys: 56.9 ms, total: 10.1 s\n",
      "Wall time: 10.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# reduce vocabulary size to make problem manageable for available computing resources\n",
    "#SEQ_VOC = 50000\n",
    "#print('Number of tokens for sequences = {}'.format(SEQ_VOC))\n",
    "\n",
    "#tokenizer = Tokenizer(num_words=VOC_SIZE, filters='!\"*,./:;?@\\`|')\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_all)\n",
    "sequences = tokenizer.texts_to_sequences(X_all)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "VOC_SIZE = len(word_index)\n",
    "print('Vocabulary size = {}'.format(VOC_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adj': 5,\n",
       " 'adp': 3,\n",
       " 'adv': 10,\n",
       " 'cconj': 9,\n",
       " 'det': 7,\n",
       " 'intj': 15,\n",
       " 'noun': 1,\n",
       " 'num': 6,\n",
       " 'part': 12,\n",
       " 'pron': 14,\n",
       " 'propn': 8,\n",
       " 'punct': 2,\n",
       " 'sym': 11,\n",
       " 'verb': 4,\n",
       " 'x': 13}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3EAAAD8CAYAAADZsi3XAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3X+MnXWd6PH3p9MurayVVmoDLdyysTZTxyzGpkvcyY1z\nuy5dMSlu1Ntms2IysRtliXvDHxT6h+4fo8VsNVeykIt3CMXIYKOrEAENYm9IEykUw1rLbC+NlDCz\npZRSqHSXXjr93D/OM3hm7HR+nTnPPGfer+TkPM/3nOc8ny9P6DOf5/srMhNJkiRJUjXMKzsASZIk\nSdLEmcRJkiRJUoWYxEmSJElShZjESZIkSVKFmMRJkiRJUoWYxEmSJElShZjESZIkSVKFmMRJkiRJ\nUoWYxEmSJElShcwvOwCASy+9NFetWlV2GJKkJnjmmWdezcxlZcdRFd4jJWlumMz9cVYkcatWrWL/\n/v1lhyFJaoKIeLHsGKrEe6QkzQ2TuT/anVKSJEmSKsQkTpIkSZIqxCROkiRJkirEJE6SJEmSKsQk\nTpIkSZIqxCROKkFfXx8dHR20tbXR0dFBX19f2SFJkiSpImbFEgPSXNLX18f27dvp7e2ls7OTvXv3\n0t3dDcCWLVtKjk6SJEmznS1xUpP19PTQ29tLV1cXCxYsoKuri97eXnp6esoOTZIkSRVgEic1WX9/\nP52dnSPKOjs76e/vLykiSZIkVYndKaUma29vZ+/evXR1db1TtnfvXtrb20uMSpIubNW2h0fsH9lx\nXUmRSJJsiZOabPv27XR3d7Nnzx7efvtt9uzZQ3d3N9u3by87NEmSJFWALXFSkw1PXnLTTTfR399P\ne3s7PT09TmoiSZKkCbElTpIkSZIqxJY4qclcYkCSJEnTYUuc1GQuMSBJkqTpMImTmswlBqTZKSIW\nRsRTEfGvEXEwIv6xKF8aEY9FxPPF+5K6Y26NiMMRcSgirq0r/0hEHCg++3ZERFF+UUR8vyjfFxGr\nml1PSVL1mcRJTTa8xEA9lxiQZoUzwH/LzD8FrgY2RsQ1wDbg8cxcDTxe7BMRa4HNwAeBjcCdEdFW\n/NZdwBeA1cVrY1HeDZzMzPcD3wJub0bFJEmtZdwkrpFPJiW5xIA0W2XNm8XuguKVwCZgV1G+C7i+\n2N4EPJCZZzLzBeAwsD4iLgMWZ+aTmZnAfaOOGf6tHwAbhlvpJEmaqIlMbDL8ZPLNiFgA7I2IR4G/\npvZkckdEbKP2ZPKWUU8mLwd+HhEfyMyhGaqDVCkuMSDNXkVL2jPA+4F/zsx9EbE8M48WX3kZWF5s\nrwCerDt8oCh7u9geXT58zEsAmXk2It4A3gu8OiqOrcBWgCuvvLIxlZMktYxxk7jiKeJYTyY/VpTv\nAv4PcAt1TyaBFyLiMLAe+GUjA5eqbMuWLSZt0ixUPHC8OiIuAX4UER2jPs+IyCbEcTdwN8C6detm\n/HySpGqZ0Ji4iGiLiGeBV4DHMnMfcKEnky/VHV7/BFKSpFkvM18H9lAby3as6CJJ8f5K8bVB4Iq6\nw1YWZYPF9ujyEcdExHzgPcCJmamFJKlVTSiJy8yhzLya2o1o/fmeTFJrnZuwiNgaEfsjYv/x48cn\nc6gkSQ0XEcuKFjgiYhHwceDfgIeAG4qv3QA8WGw/BGwuZpy8itoEJk8VDzhPRcQ1xXi3z406Zvi3\nPg38oriHSpI0YZNa7DszX4+IEU8mM/PoBJ9Mjv4tu4pIkmaTy4Bdxbi4ecDuzPxJRPwS2B0R3cCL\nwGcBMvNgROwGngPOAjfWjf/+EnAvsAh4tHgB9ALfLYYavEZtDLkkSZMybhIXEcuAt4sEbvjJ5O38\n/mniDv7wyeT9EfFNahObrAaemoHYJUlqmMz8NfDh85SfADaMcUwP0HOe8v1Ax3nK3wI+M+1gJUlz\n2kRa4hr5ZFKSJEmSNA0TmZ2yYU8mJUmSJEnTM6GJTSRJkiRJs4NJnCRJkiRViEmcJEmSJFWISZwk\nSZIkVYhJnFSCvr4+Ojo6aGtro6Ojg76+vrJDkiRJUkVMarFvSdPX19fH9u3b6e3tpbOzk71799Ld\n3Q3Ali1bSo5OkiRJs50tcVKT9fT00NvbS1dXFwsWLKCrq4ve3l56elyVQ5IkSeMziZOarL+/n87O\nzhFlnZ2d9Pf3lxSRJEmSqsQkTmqy9vZ29u7dO6Js7969tLe3lxSRJEmSqsQkTmqy7du3093dzZ49\ne3j77bfZs2cP3d3dbN++vezQJEmSVAFObCI12fDkJTfddBP9/f20t7fT09PjpCaSJEmaEJM4qQRb\ntmwxaZMkSdKU2J1SkiRJkirEJE6SJEmSKsQkTpIkSZIqxCROkiRJkirEJE6SJEmSKsQkTipBX18f\nHR0dtLW10dHRQV9fX9khSZIkqSJcYkBqsr6+PrZv305vby+dnZ3s3buX7u5uAJcdkCRJ0rhsiZOa\nrKenh97eXrq6uliwYAFdXV309vbS09NTdmiSJEmqAJM4qcn6+/sZGBgY0Z1yYGCA/v7+skOTJElS\nBdidUmqyyy+/nFtuuYXvfe9773Sn/Ju/+Rsuv/zyskOTJElSBYzbEhcRV0TEnoh4LiIORsSXi/Kv\nRsRgRDxbvD5Rd8ytEXE4Ig5FxLUzWQGpijLzgvuSmq+R97uI+EhEHCg++3ZERFF+UUR8vyjfFxGr\nml1PSVL1TaQl7ixwc2b+KiLeDTwTEY8Vn30rM/+p/ssRsRbYDHwQuBz4eUR8IDOHGhm4VFX//u//\nzr333stNN91Ef38/7e3tfOMb3+Dzn/982aFJc10j73d3AV8A9gGPABuBR4Fu4GRmvj8iNgO3A/+9\nCXWTJLWQcVviMvNoZv6q2P4d0A+suMAhm4AHMvNMZr4AHAbWNyJYqRW0t7dz6NChEWWHDh2ivb29\npIgkQePudxFxGbA4M5/MWjP7fcD1dcfsKrZ/AGwYbqWTJGmiJjWxSdHt48PUniwC3BQRv46IeyJi\nSVG2Anip7rABLnwTlOaUrq4uvv71r/Pqq6+Smbz66qt8/etfp6urq+zQJBWmeb9bUWyPLh9xTGae\nBd4A3nue82+NiP0Rsf/48eMNqZMkqXVMOImLiD8Gfgj8Q2aeotZV5E+Aq4GjwM7JnNgblOaqH//4\nxyxevJhFixYRESxatIjFixfz4x//uOzQJNH4+91UZObdmbkuM9ctW7Zspk8nSaqYCSVxEbGA2g3t\ne5n5LwCZeSwzhzLzHPAdft9lchC4ou7wlUXZCN6gNFcNDAzwxS9+kYsvvhiAiy++mC9+8YsMDAyM\nc6Skmdag+91gsT26fMQxETEfeA9wYmZqI0lqVROZnTKAXqA/M79ZV35Z3dc+Bfym2H4I2FzMwHUV\nsBp4qnEhS9V35513cvr0aTKT06dPc+edd5YdkjTnNep+l5lHgVMRcU3xm58DHqw75oZi+9PAL9Lp\naSVJkzSR2Sn/HPhb4EBEPFuU3QZsiYirgQSOAH8HkJkHI2I38By1mb5udGZK6ffa2tp44403WLhw\nIZnJf/7nf/LGG2/Q1tZWdmjSXNfI+92XgHuBRdRmpXy0KO8FvhsRh4HXqM1uKUnSpIybxGXmXuB8\nM2c9coFjeoCeacQltayhod8/06iflK6+XFLzNfJ+l5n7gY7zlL8FfGYaYUqSNLnZKSU1xkc/+lFe\nf/11MpPXX3+dj370o2WHJEmSpIowiZNKsG/fPr72ta9x+vRpvva1r7Fv377xD5IkSZIwiZOabv78\n+SxcuJA77riDd7/73dxxxx0sXLiQ+fMnMkRVkiRJc51JnNRkQ0NDLFq0aETZokWLHBMnSZKkCTGJ\nk5ps7dq1dHZ2cvToUc6dO8fRo0fp7Oxk7dq1ZYcmSZKkCjCJk5qsq6uLBx98kLNnzwJw9uxZHnzw\nQbq6ukqOTJIkSVVgEic12f33309mvtN9cmhoiMzk/vvvLzkySZq4VdsefuclSWoukzipyV577TXm\nzZvHzp07OX36NDt37mTevHm89tprZYcmSZKkCjCJk0qwZs0abrvtNi6++GJuu+021qxZU3ZIkiRJ\nqgiTOKkE/f39vOtd7wLgXe96F/39/SVHJEmSpKowiZNKNG+e/wtKkiRpclxdWCrJyZMnR7xLkiRJ\nE2EzgFSStra2Ee+SJEnSRJjESSWICC699FIALr30UiKi5IgkSZJUFSZxUgkykxMnTgBw4sQJMrPk\niCRJklQVJnFSk0UEGzZsYM2aNcybN481a9awYcMGW+MkSZI0IU5sIjVZZrJnzx7e9773AbWWuP7+\nflvjJM06q7Y9PKXvHdlx3UyEI0kq2BInNdnKlStZuHAhJ06c4Ny5c5w4cYKFCxeycuXKskOTJElS\nBZjESSUY3epmK5wkSZImyiROarLBwUHeeustli5dSkSwdOlS3nrrLQYHB8sOTZIkSRVgEieV4JJL\nLuHYsWNkJseOHeOSSy4pOyRJkiRVhBObSE2WmZw8eXJE2eh9SZIkaSzjtsRFxBURsScinouIgxHx\n5aJ8aUQ8FhHPF+9L6o65NSIOR8ShiLh2JisgVdWSJUuYN28eS5YsGf/LkiRJUmEi3SnPAjdn5lrg\nGuDGiFgLbAMez8zVwOPFPsVnm4EPAhuBOyOibSaCl6rs1KlTnDt3jlOnTpUdiiRJkipk3CQuM49m\n5q+K7d8B/cAKYBOwq/jaLuD6YnsT8EBmnsnMF4DDwPpGBy5V3dDQ0Ih3SeVqZM+TiPhIRBwoPvt2\nRERRflFEfL8o3xcRq5pdT0lS9U1qYpPiZvNhYB+wPDOPFh+9DCwvtlcAL9UdNlCUSaqzYMGCEe+S\nStfInid3AV8AVhevjUV5N3AyM98PfAu4vRkVkyS1lgkncRHxx8APgX/IzBH9v7K2yNWkFrqKiK0R\nsT8i9h8/fnwyh0ot4e233x7xLqlcjep5EhGXAYsz88ni/njfqGOGf+sHwIbhVjpJkiZqQklcRCyg\nlsB9LzP/pSg+VtyoKN5fKcoHgSvqDl9ZlI2QmXdn5rrMXLds2bKpxi9JUsNNs+fJimJ7dPmIYzLz\nLPAG8N7znN8HnZKkMU1kdsoAeoH+zPxm3UcPATcU2zcAD9aVby76/V9FrRvJU40LWWoNO3fu5PTp\n0+zcubPsUCTVaXTPk6nwQack6UImsk7cnwN/CxyIiGeLstuAHcDuiOgGXgQ+C5CZByNiN/ActfEF\nN2amMzdIo9x8883cfPPNZYchqc6Fep5k5tEJ9jwZLLZHl9cfMxAR84H3ACdmpDKSpJY1bhKXmXuB\nsfrrbxjjmB6gZxpxSS0rIqg9zP/DcknlmUDPkx38Yc+T+yPim8DlFD1PMnMoIk5FxDXUumN+Drhj\n1G/9Evg08Is83z8IkiRdwERa4iTNgCVLlnDy5Ml33iWVrpE9T74E3AssAh4tXlBLEr8bEYeB16jN\nbilJ0qSYxElNlpl88pOf5LHHHgPgP/7jP/jkJz/JT37yk5Ijk+a2RvY8ycz9QMd5yt8CPjONMCVJ\nmtw6cZIa44knnuDMmTMAnDlzhieeeKLkiCRJklQVJnFSk0UEp06doq2ttiZwW1sbp06dckycJEmS\nJsTulFKTDc9hMJy0Db87t4GkVrFq28PvbB/ZcV2JkUhSa7IlTirBhz70IYaGavMfDA0N8aEPfajk\niCRJklQVJnFSCQ4cOMDy5cuZN28ey5cv58CBA2WHJEmSpIqwO6VUkpdffnnEuyRJkjQRtsRJkiRJ\nUoWYxEklmTdv3oh3SZIkaSL861Eqyblz50a8S5IkSRNhEidJkiRJFeLEJpIkqWlcQ06Sps+WOEmS\nJEmqEJM4SZIkSaoQu1NKkqR31Hd3lCTNTrbESZIkSVKFmMRJJWlra2PevHm0tbWVHYokSZIqxO6U\nUkmGhobKDkGSJEkVZEucJEmSJFWISZwkSZIkVYjdKSVJ0oxxtktJarxxW+Ii4p6IeCUiflNX9tWI\nGIyIZ4vXJ+o+uzUiDkfEoYi4dqYClyRJkqS5aCLdKe8FNp6n/FuZeXXxegQgItYCm4EPFsfcGRFO\nvSdJkiRJDTJuEpeZTwCvTfD3NgEPZOaZzHwBOAysn0Z8kiRJkqQ605nY5KaI+HXR3XJJUbYCeKnu\nOwNFmSRJs1qjhg9ExEci4kDx2bcjIoryiyLi+0X5vohY1cz6SZJax1STuLuAPwGuBo4COyf7AxGx\nNSL2R8T+48ePTzEMSZIa5l4aM3zgLuALwOriNfyb3cDJzHw/8C3g9pmqiCSptU0picvMY5k5lJnn\ngO/w+y6Tg8AVdV9dWZSd7zfuzsx1mblu2bJlUwlDkqSGacTwgYi4DFicmU9mZgL3AdfXHbOr2P4B\nsGG4lU6SpMmYUhJX3KSGfQoY7nryELC56DJyFbUnkE9NL0RJkko1meEDK4rt0eUjjsnMs8AbwHtn\nMnBJUmuayBIDfcAvgTURMRAR3cA3iv7+vwa6gP8BkJkHgd3Ac8BPgRszc2jGopckaWZNe/jAVDjk\nQJJ0IeMu9p2ZW85T3HuB7/cAPdMJSpKk2SAzjw1vR8R3gJ8Uu2MNHxgstkeX1x8zEBHzgfcAJ8Y4\n793A3QDr1q3LaVdEktRSpjM7pSRJLW2ywwcy8yhwKiKuKca7fQ54sO6YG4rtTwO/KMbNSZI0KeO2\nxEmSNBcUwwc+BlwaEQPAV4CPRcTVQAJHgL+D2vCBiBgePnCWkcMHvkRtpstFwKPFC2q9WL4bEYep\nTaCyeeZrJUlqRSZxkiTRuOEDmbkf6DhP+VvAZ6YToyRJYHdKSZIkSaoUkzhJkiRJqhCTOEmSJEmq\nEJM4SZIkSaoQkzhJkiRJqhCTOEmSJEmqEJM4SZIkSaoQkzhJkiRJqhCTOEmSJEmqEJM4SZIkSaoQ\nkzhJkiRJqhCTOEmSJEmqEJM4SZIkSaoQkzhJkiRJqhCTOEmSJEmqEJM4SZIkSaqQ+WUHIEmSyrNq\n28NlhyBJmiRb4iRJkiSpQkziJEmSJKlCxk3iIuKeiHglIn5TV7Y0Ih6LiOeL9yV1n90aEYcj4lBE\nXDtTgUuSJEnSXDSRlrh7gY2jyrYBj2fmauDxYp+IWAtsBj5YHHNnRLQ1LFpJkiRJmuPGTeIy8wng\ntVHFm4BdxfYu4Pq68gcy80xmvgAcBtY3KFZJkiRJmvOmOiZueWYeLbZfBpYX2yuAl+q+N1CUSZIk\nSZIaYNoTm2RmAjnZ4yJia0Tsj4j9x48fn24YkiRJkjQnTDWJOxYRlwEU768U5YPAFXXfW1mU/YHM\nvDsz12XmumXLlk0xDEmSGqNRE3lFxEci4kDx2bcjIoryiyLi+0X5vohY1cz6SZJax1STuIeAG4rt\nG4AH68o3Fzeqq4DVwFPTC1GSpKa4l8ZM5HUX8AVq98DVdb/ZDZzMzPcD3wJun7GaSJJa2kSWGOgD\nfgmsiYiBiOgGdgAfj4jngb8o9snMg8Bu4Dngp8CNmTk0U8FLktQojZjIq+idsjgznyyGG9w36pjh\n3/oBsGG4lU6SpMmYP94XMnPLGB9tGOP7PUDPdIKSJGmWuNBEXk/WfW94Iq+3i+3R5cPHvASQmWcj\n4g3gvcCrMxO6JKlVjZvESZKk2kReETHpibymIiK2AlsBrrzyymacshSrtj08Yv/IjutKikSSqmXa\ns1NKktTCJjuR12CxPbp8xDERMR94D3DifCd18i9J0oWYxEmSNLZJTeRVdL08FRHXFOPdPjfqmOHf\n+jTwi2LcnCRJk2J3SkmSeGcir48Bl0bEAPAVahN37S4m9XoR+CzUJvKKiOGJvM4yciKvL1Gb6XIR\n8GjxAugFvhsRh6lNoLK5CdWSJLUgkzhJkmjcRF6ZuR/oOE/5W8BnphOjJElgd0pJkiRJqhSTOEmS\nJEmqEJM4SZIkSaoQkzhJkiRJqhCTOEmSJEmqEJM4SZIkSaoQlxiQJEmzwqptD7+zfWTHdSVGIkmz\nmy1xkiRJklQhJnGSJEmSVCEmcZIkSZJUISZxkiRJklQhJnGSJEmSVCEmcZIkSZJUIS4xIE1TRJTy\nW5nZsPNKkiSpOkzipGmabDJ1oUTNxEySJEnjsTul1GRjJWomcJIkSZoIW+KkEgwnbBFh8iZJkqRJ\nmVYSFxFHgN8BQ8DZzFwXEUuB7wOrgCPAZzPz5PTClCRJc8mqbQ+P2D+y47qSIpGk2acR3Sm7MvPq\nzFxX7G8DHs/M1cDjxb4kSZIkqQFmYkzcJmBXsb0LuH4GziFJkiRJc9J0k7gEfh4Rz0TE1qJseWYe\nLbZfBpZP8xySJEmSpMJ0JzbpzMzBiHgf8FhE/Fv9h5mZEXHeWRuKpG8rwJVXXjnNMCRJkiRpbphW\nS1xmDhbvrwA/AtYDxyLiMoDi/ZUxjr07M9dl5rply5ZNJwxJkiRJmjOmnMRFxMUR8e7hbeAvgd8A\nDwE3FF+7AXhwukFKkiRJkmqm0xK3HNgbEf8KPAU8nJk/BXYAH4+I54G/KPYlSaqsiDgSEQci4tmI\n2F+ULY2IxyLi+eJ9Sd33b42IwxFxKCKurSv/SPE7hyPi2xERZdRHklRtUx4Tl5m/Bf70POUngA3T\nCUqSpFmoKzNfrdsfXlJnR0RsK/ZviYi1wGbgg8Dl1CYA+0BmDgF3AV8A9gGPABuBR5tZCfjDNdiq\nxjXkJM11M7HEgCRJc8FYS+psAh7IzDOZ+QJwGFhfjBNfnJlPZmYC9+EyPJKkKZju7JSSJM0Fw0vq\nDAH/KzPvZuwldVYAT9YdO1CUvV1sjy7XBFS99VCSGskkTpKk8U15SZ2pcBkeSdKF2J1SkqRxTHJJ\nnUHgirrDVxZlg8X26PLznc9leCRJYzKJkwpLly4lIpr6App6vqVLl5b8X1mqniksqfMQsDkiLoqI\nq4DVwFNF18tTEXFNMSvl53AZHknSFNidUiqcPHmS2lwDrcvZzKUpWQ78qPj/Zz5wf2b+NCKeBnZH\nRDfwIvBZgMw8GBG7geeAs8CNxcyUAF8C7gUWUZuVsukzU0qSqs8kTpKkC5jKkjqZ2QP0nKd8P9DR\n6BglSXOL3SklSZIkqUJM4iRJkiSpQkziJEmSJKlCTOIkSZIkqUKc2EQq5FcWw1ffU3YYMyq/srjs\nECRJkjRNJnFSIf7x1JxYYiC/WnYUkiRJmg67U0qSJElShdgSJ0mSKm3Vtoff2T6y47oSI5Gk5jCJ\nk+pERNkhzKglS5aUHYIkSZKmySROKpQxHi4iWn4cniRJkhrLMXGSJEmSVCG2xEmSpJbh+DhJc4Et\ncZIkSZJUIbbESZLU4upbpyRJ1WcSJ0mSWtLo5NXulZJaxYx1p4yIjRFxKCIOR8S2mTqPJEmSJM0l\nM5LERUQb8M/AXwFrgS0RsXYmziVJkiRJc8lMdadcDxzOzN8CRMQDwCbguRk6nyRJ0gU5c6WkVjFT\nSdwK4KW6/QHgz2boXFKpIqKU410kXJIkaW4qbWKTiNgKbAW48sorywpDmjaTKUmqngvN2GkrnaTZ\nbqYmNhkErqjbX1mUvSMz787MdZm5btmyZTMUhiRJkiS1lplK4p4GVkfEVRHxR8Bm4KEZOpckSZIk\nzRkz0p0yM89GxN8DPwPagHsy8+BMnEuSJKmRXF9O0mw3Y2PiMvMR4JGZ+n1JkqRmcFZLSbNNaROb\nSJI0F0XERuB/Uuup8r8zc0fJIWkSLtRKZwuepGYxiZMkqUkiog34Z+Dj1JbfeToiHspM11GtqAvN\ncilJM8UkTpKk5lkPHM7M3wJExAPAJsAkrgVNNMGzNU/SZJnESZLUPCuAl+r2B4A/KykWzRIXSvZm\nuqXPJFGqplmRxD3zzDOvRsSLZcchleBS4NWyg5Ca7L+UHcBsFxFbga3F7psRcWgaP9eq/860ar2g\niXWL25txlne06jWzXtUym+s14fvjrEjiMtPVvjUnRcT+zFxXdhySmmYQuKJuf2VRNkJm3g3c3YgT\ntuq/M61aL2jdulmvarFes9tMLfYtSZL+0NPA6oi4KiL+CNgMPFRyTJKkipkVLXGSJM0FmXk2Iv4e\n+Bm1JQbuycyDJYclSaoYkzipXA3pLiWpOjLzEeCRJp6yVf+dadV6QevWzXpVi/WaxSIzy45BkiRJ\nkjRBjomTJEmSpAoxiZOaLCLuiYhXIuI3ZcciqbVFxMaIOBQRhyNiW9nxTEdEHImIAxHxbETsL8qW\nRsRjEfF88b6k7DjHc757wIXqERG3FtfvUERcW07U4xujXl+NiMHimj0bEZ+o+6wq9boiIvZExHMR\ncTAivlyUV/qaXaBerXDNFkbEUxHxr0Xd/rEor/Q1G83ulFKTRcR/Bd4E7svMjrLjkdSaIqIN+L/A\nx6ktKv40sCUznys1sCmKiCPAusx8ta7sG8BrmbmjSFKXZOYtZcU4Eee7B4xVj4hYC/QB64HLgZ8D\nH8jMoZLCH9MY9foq8GZm/tOo71apXpcBl2XmryLi3cAzwPXA56nwNbtAvT5L9a9ZABdn5psRsQDY\nC3wZ+GsqfM1GsyVOarLMfAJ4rew4JLW89cDhzPxtZv4/4AFgU8kxNdomYFexvYvaH6Gz2hj3gLHq\nsQl4IDPPZOYLwGFq13XWmeS9rUr1OpqZvyq2fwf0Ayuo+DW7QL3GUol6AWTNm8XuguKVVPyajWYS\nJ0lSa1oBvFS3P8CF/0ib7RL4eUQ8ExFbi7LlmXm02H4ZWF5OaNM2Vj1a4RreFBG/LrpbDndfq2S9\nImIV8GFgHy10zUbVC1rgmkVEW0Q8C7wCPJaZLXXNwCROkiRVQ2dmXg38FXBj0X3vHVkbH1L5MSKt\nUo/CXcCfAFcDR4Gd5YYzdRHxx8APgX/IzFP1n1X5mp2nXi1xzTJzqPj3YiWwPiI6Rn1e2Ws2zCRO\nkqTWNAhcUbe/siirpMwcLN5fAX5ErbvTsWJsz/AYn1fKi3BaxqpHpa9hZh4r/pg+B3yH33dRq1S9\ninFVPwS+l5n/UhRX/pqdr16tcs2GZebrwB5gIy1wzeqZxEmS1JqeBlZHxFUR8UfAZuChkmOakoi4\nuJh8gYi4GPhL4DfU6nND8bUbgAfLiXDaxqrHQ8DmiLgoIq4CVgNPlRDflAz/wVz4FLVrBhWqVzFJ\nRi/Qn5mDjmzkAAABAklEQVTfrPuo0tdsrHq1yDVbFhGXFNuLqE3u9G9U/JqNNr/sAKS5JiL6gI8B\nl0bEAPCVzOwtNypJrSYzz0bE3wM/A9qAezLzYMlhTdVy4Ee1vzuZD9yfmT+NiKeB3RHRDbxIbWa9\nWe189wBgB+epR2YejIjdwHPAWeDG2Tpj3hj1+lhEXE2t29oR4O+gWvUC/hz4W+BAMcYK4Daqf83G\nqteWFrhmlwG7ihl65wG7M/MnEfFLqn3NRnCJAUmSJEmqELtTSpIkSVKFmMRJkiRJUoWYxEmSJElS\nhZjESZIkSVKFmMRJkiRJUoWYxEmSJElShZjESZIkSVKFmMRJkiRJUoX8f+v6O59+JPVuAAAAAElF\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e658eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seq_len = [len(seq) for seq in sequences]\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 4))\n",
    "axes[0].boxplot(seq_len)\n",
    "axes[1].hist(seq_len, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240387, 120)\n"
     ]
    }
   ],
   "source": [
    "MAX_SEQ_LEN = 120\n",
    "X_token_seq_all = pad_sequences(sequences, maxlen=MAX_SEQ_LEN, dtype='int32', padding='pre', truncating='post', value=0)\n",
    "print(X_token_seq_all.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize output labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.03 s, sys: 59.5 ms, total: 2.09 s\n",
      "Wall time: 2.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "labels = df_all.label.values\n",
    "label_dict = {label: no for no, label in enumerate(set(labels))}\n",
    "number_of_classes = len(label_dict)\n",
    "\n",
    "# get labels as integers\n",
    "y_all = [label_dict[label] for label in labels]\n",
    "\n",
    "# change y to categorical (vectorize output)\n",
    "y_all = np.array([to_categorical(i, num_classes=number_of_classes) for i in y_all])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Onehot encode POS TAG labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240387, 120)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 8, 2, 2],\n",
       "       [0, 0, 0, ..., 6, 1, 2],\n",
       "       [0, 0, 0, ..., 1, 1, 2],\n",
       "       ..., \n",
       "       [0, 0, 0, ..., 1, 6, 2],\n",
       "       [0, 0, 0, ..., 4, 4, 2],\n",
       "       [0, 0, 0, ..., 8, 1, 2]], dtype=int32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_token_seq_all.shape)\n",
    "X_token_seq_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240387, 1800)\n",
      "(240387, 1800)\n",
      "CPU times: user 2min 10s, sys: 2.15 s, total: 2min 12s\n",
      "Wall time: 2min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "EMBEDDING_DIM = VOC_SIZE\n",
    "\n",
    "def get_vector(token):\n",
    "    vector = np.zeros(EMBEDDING_DIM)\n",
    "    if token != 0:\n",
    "        vector[token-1] = 1\n",
    "    return vector\n",
    "\n",
    "X_token_seq_all_v = np.zeros((X_token_seq_all.shape[0], X_token_seq_all.shape[1] * EMBEDDING_DIM))\n",
    "print(X_token_seq_all_v.shape)\n",
    "i = 0\n",
    "for token_seq in X_token_seq_all:\n",
    "    X_token_seq_all_v[i] = np.array([get_vector(token) for token in token_seq]).flatten()\n",
    "    i += 1\n",
    "    \n",
    "print(X_token_seq_all_v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 120, 15)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 116, 64)           4864      \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 112, 64)           20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 22, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 18, 128)           41088     \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 14, 128)           82048     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "sentence_vector_1 (Dense)    (None, 100)               12900     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 505       \n",
      "=================================================================\n",
      "Total params: 161,949\n",
      "Trainable params: 161,949\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 180040 samples, validate on 30212 samples\n",
      "Epoch 1/20\n",
      "180040/180040 [==============================] - 386s 2ms/step - loss: 1.1249 - acc: 0.5252 - val_loss: 0.9131 - val_acc: 0.6431\n",
      "Epoch 2/20\n",
      "180040/180040 [==============================] - 351s 2ms/step - loss: 0.9290 - acc: 0.6385 - val_loss: 0.8636 - val_acc: 0.6651\n",
      "Epoch 3/20\n",
      "180040/180040 [==============================] - 305s 2ms/step - loss: 0.8859 - acc: 0.6593 - val_loss: 0.8286 - val_acc: 0.6790\n",
      "Epoch 4/20\n",
      "180040/180040 [==============================] - 313s 2ms/step - loss: 0.8578 - acc: 0.6710 - val_loss: 0.8177 - val_acc: 0.6822\n",
      "Epoch 5/20\n",
      "180040/180040 [==============================] - 313s 2ms/step - loss: 0.8377 - acc: 0.6811 - val_loss: 0.8069 - val_acc: 0.6896\n",
      "Epoch 6/20\n",
      "180040/180040 [==============================] - 310s 2ms/step - loss: 0.8224 - acc: 0.6875 - val_loss: 0.8062 - val_acc: 0.6902\n",
      "Epoch 7/20\n",
      "180040/180040 [==============================] - 312s 2ms/step - loss: 0.8082 - acc: 0.6919 - val_loss: 0.8137 - val_acc: 0.6846\n",
      "CPU times: user 1h 11min 18s, sys: 9min 33s, total: 1h 20min 51s\n",
      "Wall time: 38min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# implementing 1D convolution ann as decribed in Keras tutorial\n",
    "# https://keras.io/getting-started/sequential-model-guide/\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv1D, Input, Flatten, Dropout, Dense, MaxPooling1D, GlobalAveragePooling1D\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# reshape input to apply convolution\n",
    "KERNEL_SIZE = 5\n",
    "\n",
    "X_seq_input = X_token_seq_all_v.reshape(X_token_seq_all_v.shape[0], MAX_SEQ_LEN, EMBEDDING_DIM)\n",
    "\n",
    "postags = Input(shape=(MAX_SEQ_LEN, EMBEDDING_DIM), dtype='float32')\n",
    "C1 = Conv1D(64, KERNEL_SIZE, activation='relu')(postags)\n",
    "C1 = Conv1D(64, KERNEL_SIZE, activation='relu')(C1)\n",
    "C1 = MaxPooling1D(KERNEL_SIZE)(C1)\n",
    "C1 = Conv1D(128, KERNEL_SIZE, activation='relu')(C1)\n",
    "C1 = Conv1D(128, KERNEL_SIZE, activation='relu')(C1)\n",
    "C1 = GlobalAveragePooling1D()(C1)\n",
    "C1 = Dropout(0.5)(C1)\n",
    "C1 = Dense(100, activation='relu', name='sentence_vector_1')(C1)\n",
    "C1 = Dropout(0.5)(C1)\n",
    "preds = Dense(5, activation='softmax')(C1)\n",
    "\n",
    "model = Model(postags, preds)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# learn\n",
    "model.fit(X_seq_input[:X_train_cnt], y_all[:X_train_cnt], \\\n",
    "          validation_data=(X_seq_input[X_train_cnt:(X_train_cnt+X_valid_cnt)], \\\n",
    "                                 y_all[X_train_cnt:(X_train_cnt+X_valid_cnt)]), \\\n",
    "          callbacks=[EarlyStopping(patience=1, monitor='val_loss')], \\\n",
    "          verbose=1, epochs=20, batch_size=256)\n",
    "\n",
    "model1 = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 120, 15)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 118, 64)           2944      \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 116, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 38, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 36, 128)           24704     \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 34, 128)           49280     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_2 ( (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "sentence_vector_1 (Dense)    (None, 100)               12900     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 505       \n",
      "=================================================================\n",
      "Total params: 102,685\n",
      "Trainable params: 102,685\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 180040 samples, validate on 30212 samples\n",
      "Epoch 1/20\n",
      "180040/180040 [==============================] - 291s 2ms/step - loss: 1.1540 - acc: 0.5062 - val_loss: 0.9326 - val_acc: 0.6353\n",
      "Epoch 2/20\n",
      "180040/180040 [==============================] - 290s 2ms/step - loss: 0.9552 - acc: 0.6258 - val_loss: 0.8833 - val_acc: 0.6582\n",
      "Epoch 3/20\n",
      "180040/180040 [==============================] - 284s 2ms/step - loss: 0.9121 - acc: 0.6462 - val_loss: 0.8498 - val_acc: 0.6715\n",
      "Epoch 4/20\n",
      "180040/180040 [==============================] - 288s 2ms/step - loss: 0.8864 - acc: 0.6575 - val_loss: 0.8317 - val_acc: 0.6778\n",
      "Epoch 5/20\n",
      "180040/180040 [==============================] - 285s 2ms/step - loss: 0.8707 - acc: 0.6646 - val_loss: 0.8211 - val_acc: 0.6834\n",
      "Epoch 6/20\n",
      "180040/180040 [==============================] - 286s 2ms/step - loss: 0.8555 - acc: 0.6725 - val_loss: 0.8116 - val_acc: 0.6869\n",
      "Epoch 7/20\n",
      "180040/180040 [==============================] - 370s 2ms/step - loss: 0.8427 - acc: 0.6788 - val_loss: 0.8045 - val_acc: 0.6895\n",
      "Epoch 8/20\n",
      "180040/180040 [==============================] - 376s 2ms/step - loss: 0.8343 - acc: 0.6817 - val_loss: 0.7996 - val_acc: 0.6876\n",
      "Epoch 9/20\n",
      "180040/180040 [==============================] - 378s 2ms/step - loss: 0.8239 - acc: 0.6852 - val_loss: 0.8008 - val_acc: 0.6902\n",
      "CPU times: user 1h 31min 13s, sys: 11min 7s, total: 1h 42min 21s\n",
      "Wall time: 47min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# implementing 1D convolution ann as decribed in Keras tutorial\n",
    "# https://keras.io/getting-started/sequential-model-guide/\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv1D, Input, Flatten, Dropout, Dense, MaxPooling1D, GlobalAveragePooling1D\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# reshape input to apply convolution\n",
    "KERNEL_SIZE = 3\n",
    "\n",
    "X_seq_input = X_token_seq_all_v.reshape(X_token_seq_all_v.shape[0], MAX_SEQ_LEN, EMBEDDING_DIM)\n",
    "\n",
    "postags = Input(shape=(MAX_SEQ_LEN, EMBEDDING_DIM), dtype='float32')\n",
    "C1 = Conv1D(64, KERNEL_SIZE, activation='relu')(postags)\n",
    "C1 = Conv1D(64, KERNEL_SIZE, activation='relu')(C1)\n",
    "C1 = MaxPooling1D(KERNEL_SIZE)(C1)\n",
    "C1 = Conv1D(128, KERNEL_SIZE, activation='relu')(C1)\n",
    "C1 = Conv1D(128, KERNEL_SIZE, activation='relu')(C1)\n",
    "C1 = GlobalAveragePooling1D()(C1)\n",
    "C1 = Dropout(0.5)(C1)\n",
    "C1 = Dense(100, activation='relu', name='sentence_vector_1')(C1)\n",
    "C1 = Dropout(0.5)(C1)\n",
    "preds = Dense(5, activation='softmax')(C1)\n",
    "\n",
    "model = Model(postags, preds)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# learn\n",
    "model.fit(X_seq_input[:X_train_cnt], y_all[:X_train_cnt], \\\n",
    "          validation_data=(X_seq_input[X_train_cnt:(X_train_cnt+X_valid_cnt)], \\\n",
    "                                 y_all[X_train_cnt:(X_train_cnt+X_valid_cnt)]), \\\n",
    "          callbacks=[EarlyStopping(patience=1, monitor='val_loss')], \\\n",
    "          verbose=1, epochs=20, batch_size=256)\n",
    "\n",
    "model2 = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 120, 15)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 119, 64)           1984      \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 118, 64)           8256      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 59, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 58, 128)           16512     \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 57, 128)           32896     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_3 ( (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "sentence_vector_1 (Dense)    (None, 100)               12900     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 505       \n",
      "=================================================================\n",
      "Total params: 73,053\n",
      "Trainable params: 73,053\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 180040 samples, validate on 30212 samples\n",
      "Epoch 1/20\n",
      "180040/180040 [==============================] - 273s 2ms/step - loss: 1.1833 - acc: 0.4947 - val_loss: 0.9951 - val_acc: 0.6006\n",
      "Epoch 2/20\n",
      "180040/180040 [==============================] - 263s 1ms/step - loss: 0.9886 - acc: 0.6079 - val_loss: 0.9263 - val_acc: 0.6322\n",
      "Epoch 3/20\n",
      "180040/180040 [==============================] - 264s 1ms/step - loss: 0.9312 - acc: 0.6375 - val_loss: 0.8714 - val_acc: 0.6644\n",
      "Epoch 4/20\n",
      "180040/180040 [==============================] - 290s 2ms/step - loss: 0.9076 - acc: 0.6507 - val_loss: 0.8454 - val_acc: 0.6760\n",
      "Epoch 5/20\n",
      "180040/180040 [==============================] - 283s 2ms/step - loss: 0.8902 - acc: 0.6567 - val_loss: 0.8385 - val_acc: 0.6783\n",
      "Epoch 6/20\n",
      "180040/180040 [==============================] - 258s 1ms/step - loss: 0.8762 - acc: 0.6635 - val_loss: 0.8427 - val_acc: 0.6714\n",
      "CPU times: user 57min 3s, sys: 6min 4s, total: 1h 3min 8s\n",
      "Wall time: 27min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# implementing 1D convolution ann as decribed in Keras tutorial\n",
    "# https://keras.io/getting-started/sequential-model-guide/\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv1D, Input, Flatten, Dropout, Dense, MaxPooling1D, GlobalAveragePooling1D\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# reshape input to apply convolution\n",
    "KERNEL_SIZE = 2\n",
    "\n",
    "X_seq_input = X_token_seq_all_v.reshape(X_token_seq_all_v.shape[0], MAX_SEQ_LEN, EMBEDDING_DIM)\n",
    "\n",
    "postags = Input(shape=(MAX_SEQ_LEN, EMBEDDING_DIM), dtype='float32')\n",
    "C1 = Conv1D(64, KERNEL_SIZE, activation='relu')(postags)\n",
    "C1 = Conv1D(64, KERNEL_SIZE, activation='relu')(C1)\n",
    "C1 = MaxPooling1D(KERNEL_SIZE)(C1)\n",
    "C1 = Conv1D(128, KERNEL_SIZE, activation='relu')(C1)\n",
    "C1 = Conv1D(128, KERNEL_SIZE, activation='relu')(C1)\n",
    "C1 = GlobalAveragePooling1D()(C1)\n",
    "C1 = Dropout(0.5)(C1)\n",
    "C1 = Dense(100, activation='relu', name='sentence_vector_1')(C1)\n",
    "C1 = Dropout(0.5)(C1)\n",
    "preds = Dense(5, activation='softmax')(C1)\n",
    "\n",
    "model = Model(postags, preds)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# learn\n",
    "model.fit(X_seq_input[:X_train_cnt], y_all[:X_train_cnt], \\\n",
    "          validation_data=(X_seq_input[X_train_cnt:(X_train_cnt+X_valid_cnt)], \\\n",
    "                                 y_all[X_train_cnt:(X_train_cnt+X_valid_cnt)]), \\\n",
    "          callbacks=[EarlyStopping(patience=1, monitor='val_loss')], \\\n",
    "          verbose=1, epochs=20, batch_size=256)\n",
    "\n",
    "model3 = model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model1.save('input/Extension_Part1_CONV1_POS_TAG1.h5')\n",
    "model2.save('input/Extension_Part1_CONV1_POS_TAG2.h5')\n",
    "model3.save('input/Extension_Part1_CONV1_POS_TAG3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
