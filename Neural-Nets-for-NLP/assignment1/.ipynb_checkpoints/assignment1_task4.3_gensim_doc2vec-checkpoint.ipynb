{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L665 ML for NLPSpring 2018 \n",
    "\n",
    "## Assignment 1 - Task 4, notebook 3 of 3: doc2vec exploration with gensim\n",
    "\n",
    "Author: Carlos Sathler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read toxic comments dataset and create train and test partitions\n",
    "\n",
    "Source: Kaggle Toxic Comment Classification Challenge (https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all = pd.read_csv('input/train.csv')\n",
    "drop_cols = ['id', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "df_all = df_all.drop(drop_cols, axis=1)\n",
    "#df_all = df_all.sample(frac=0.2)\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of toxic comments: 0.09584448302009764\n"
     ]
    }
   ],
   "source": [
    "print('Percentage of toxic comments: {}'.format(df_all['toxic'].sum() / df_all['toxic'].count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize text\n",
    "import re\n",
    "pat = re.compile(u'[^a-zA-Z0-9]')\n",
    "def normalize(txt):\n",
    "    return pat.sub(' ',txt)\n",
    "    \n",
    "df_all['comment_text'] = df_all['comment_text'].apply(lambda x: normalize(x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create train, test partitions\n",
    "X_all = df_all.comment_text.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, df_all.toxic.values, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create benchmark using BOW (and GradientBoostingClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(111699, 4873)\n",
      "(47872, 4873)\n",
      "CPU times: user 1min 20s, sys: 2.42 s, total: 1min 22s\n",
      "Wall time: 1min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# extract BOW as tfidf sparce matrix\n",
    "vectorizer = TfidfVectorizer(\\\n",
    "                             ngram_range=(1,3),\n",
    "                             stop_words='english',\n",
    "                             min_df=0.001,\n",
    "                             max_df=0.99,\n",
    "                             sublinear_tf=True\n",
    "                            )\n",
    "vectorizer.fit(X_all)\n",
    "X_train_csr = vectorizer.transform(X_train)\n",
    "X_test_csr = vectorizer.transform(X_test)\n",
    "print(X_train_csr.shape)\n",
    "print(X_test_csr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.9548379010695187\n",
      "CPU times: user 1.64 s, sys: 107 ms, total: 1.75 s\n",
      "Wall time: 1.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# train and predict\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_csr, y_train)\n",
    "y_hat = clf.predict(X_test_csr)\n",
    "acc = accuracy_score(y_test, y_hat)\n",
    "print(\"Accuracy = {}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create doc2vec using gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01:28:02 => Doc2Vec for feature \"comment_text\"\n",
      "01:28:02 => Extracting sentences...\n",
      "01:28:06 => Building vocabulary...\n",
      "01:28:18 => Training doc2vec model...\n",
      "02:15:47 => Doc2Vec for feature \"comment_text\"\n",
      "02:15:47 => Extracting sentences...\n",
      "02:15:49 => Building vocabulary...\n",
      "02:15:56 => Training doc2vec model...\n",
      "(111699, 1000)\n",
      "(47872, 1000)\n",
      "CPU times: user 3h 49min 38s, sys: 25min 32s, total: 4h 15min 10s\n",
      "Wall time: 1h 12min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def print_msg(msg):\n",
    "    print('{} => {}'.format(strftime(\"%H:%M:%S\", gmtime()), msg))\n",
    "    \n",
    "NROWS=5000000\n",
    "\n",
    "# gensim modules\n",
    "import os\n",
    "from time import gmtime, strftime\n",
    "from gensim import utils\n",
    "from gensim.models.doc2vec import LabeledSentence\n",
    "from gensim.models import Doc2Vec\n",
    "\n",
    "# random\n",
    "from random import shuffle\n",
    "\n",
    "def get_doc2vec_model(df, fieldname, epochs=5, size=100, window=5, negative=3):\n",
    "    \n",
    "    print_msg('Doc2Vec for feature \"{}\"'.format(fieldname))\n",
    "    \n",
    "    # need to create a list in the following format:\n",
    "    # [['word1', 'word2', 'word3', 'lastword'], ['label1']]\n",
    "\n",
    "    feature_array = df[fieldname].values\n",
    "    idx = np.array(range(0,feature_array.shape[0]))\n",
    "\n",
    "    print_msg(\"Extracting sentences...\")\n",
    "\n",
    "    sentences = []\n",
    "    for i, sentence in zip(idx[:NROWS], feature_array[:NROWS]):\n",
    "        sentences.append(LabeledSentence(utils.to_unicode(sentence.lower()).split(), ['SENT_{}'.format(str(i))]))\n",
    "\n",
    "    print_msg(\"Building vocabulary...\")\n",
    "\n",
    "    model = Doc2Vec(min_count=1, window=window, size=size, sample=1e-4, negative=negative, workers=8)\n",
    "    model.build_vocab(sentences)\n",
    "    \n",
    "    print_msg(\"Training doc2vec model...\")\n",
    "\n",
    "    def get_shuffled(sentences):\n",
    "        shuffle(sentences)\n",
    "        return sentences\n",
    "\n",
    "    model.train(get_shuffled(sentences), epochs=epochs, total_examples=model.corpus_count)\n",
    "\n",
    "    del feature_array, idx, sentences\n",
    "        \n",
    "    return model\n",
    "\n",
    "df_train = pd.DataFrame(X_train, columns=(['comment_text']))\n",
    "df_test = pd.DataFrame(X_test, columns=(['comment_text']))\n",
    "model_train = get_doc2vec_model(df_train, 'comment_text', epochs=200, size=1000, window=10, negative=5)  \n",
    "model_test = get_doc2vec_model(df_test, 'comment_text', epochs=200, size=1000, window=10, negative=5)  \n",
    "\n",
    "X_train_doc2vec = np.array([ dv for dv in model_train.docvecs ])\n",
    "X_test_doc2vec = np.array([ dv for dv in model_test.docvecs ])\n",
    "\n",
    "del model_train, model_test\n",
    "gc.collect()\n",
    "\n",
    "print(X_train_doc2vec.shape)\n",
    "print(X_test_doc2vec.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append POS tag vector to BOW one-hot-encoded vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(111699, 5873)\n",
      "(47872, 5873)\n",
      "CPU times: user 11 s, sys: 4.04 s, total: 15 s\n",
      "Wall time: 15.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "from scipy.sparse import hstack\n",
    "X_train_csr_2 = hstack((X_train_csr, X_train_doc2vec)).tocsr()\n",
    "X_test_csr_2 = hstack((X_test_csr, X_test_doc2vec)).tocsr()\n",
    "print(X_train_csr_2.shape)\n",
    "print(X_test_csr_2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare AdaBoostClassifier on enhanced data against benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.9433489304812834\n",
      "CPU times: user 33min 16s, sys: 59.1 s, total: 34min 15s\n",
      "Wall time: 34min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# BOW + NLP features\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "clf = AdaBoostClassifier(n_estimators=100, learning_rate=1.0)\n",
    "clf.fit(X_train_csr_2, y_train)\n",
    "y_hat = clf.predict(X_test_csr_2)\n",
    "acc = accuracy_score(y_test, y_hat)\n",
    "print(\"Accuracy = {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.9490307486631016\n",
      "CPU times: user 38.5 s, sys: 691 ms, total: 39.2 s\n",
      "Wall time: 39.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# BOW dataset\n",
    "\n",
    "clf.fit(X_train_csr, y_train)\n",
    "y_hat = clf.predict(X_test_csr)\n",
    "acc = accuracy_score(y_test, y_hat)\n",
    "print(\"Accuracy = {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8833765040106952\n",
      "CPU times: user 29min 34s, sys: 2.36 s, total: 29min 36s\n",
      "Wall time: 29min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# doc2vec alone\n",
    "\n",
    "clf.fit(X_train_doc2vec, y_train)\n",
    "y_hat = clf.predict(X_test_doc2vec)\n",
    "acc = accuracy_score(y_test, y_hat)\n",
    "print(\"Accuracy = {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
