{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4\n",
    "\n",
    "## Task a - Baseline (LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras import regularizers\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>partition</th>\n",
       "      <th>abstract_id</th>\n",
       "      <th>seq</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>4293578</td>\n",
       "      <td>0</td>\n",
       "      <td>To investigate the efficacy of 6 weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at 12 weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .</td>\n",
       "      <td>OBJECTIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train</td>\n",
       "      <td>4293578</td>\n",
       "      <td>1</td>\n",
       "      <td>A total of 125 patients with primary knee OA were randomized 1:1 ; 63 received 7.5 mg/day of prednisolone and 62 received placebo for 6 weeks .</td>\n",
       "      <td>METHODS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train</td>\n",
       "      <td>4293578</td>\n",
       "      <td>2</td>\n",
       "      <td>Outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .</td>\n",
       "      <td>METHODS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train</td>\n",
       "      <td>4293578</td>\n",
       "      <td>3</td>\n",
       "      <td>Pain was assessed using the visual analog pain scale ( 0-100 mm ) .</td>\n",
       "      <td>METHODS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train</td>\n",
       "      <td>4293578</td>\n",
       "      <td>4</td>\n",
       "      <td>Secondary outcome measures included the Western Ontario and McMaster Universities Osteoarthritis Index scores , patient global assessment ( PGA ) of the severity of knee OA , and 6-min walk distance ( 6MWD ) .</td>\n",
       "      <td>METHODS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  partition  abstract_id  seq  \\\n",
       "0     train      4293578    0   \n",
       "1     train      4293578    1   \n",
       "2     train      4293578    2   \n",
       "3     train      4293578    3   \n",
       "4     train      4293578    4   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                         text  \\\n",
       "0  To investigate the efficacy of 6 weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at 12 weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .   \n",
       "1                                                                                                                                             A total of 125 patients with primary knee OA were randomized 1:1 ; 63 received 7.5 mg/day of prednisolone and 62 received placebo for 6 weeks .   \n",
       "2                                                                                                                                                                             Outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .   \n",
       "3                                                                                                                                                                                                                         Pain was assessed using the visual analog pain scale ( 0-100 mm ) .   \n",
       "4                                                                           Secondary outcome measures included the Western Ontario and McMaster Universities Osteoarthritis Index scores , patient global assessment ( PGA ) of the severity of knee OA , and 6-min walk distance ( 6MWD ) .   \n",
       "\n",
       "       label  \n",
       "0  OBJECTIVE  \n",
       "1    METHODS  \n",
       "2    METHODS  \n",
       "3    METHODS  \n",
       "4    METHODS  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# file PubMed_200k_RCT.csv created by script01_create_single_dataset\n",
    "df_all = pd.read_csv('input/PubMed_20k_RCT.csv')\n",
    "df_train = df_all[df_all['partition']=='train']\n",
    "df_valid = df_all[df_all['partition']=='dev']\n",
    "df_test = df_all[df_all['partition']=='test']\n",
    "pd.set_option('max_colwidth',500)\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train partition size: 180040\n",
      "Valid partition size: 30212\n",
      "Test partition size: 30135\n",
      "Total dataset size: 240387\n"
     ]
    }
   ],
   "source": [
    "X_train_cnt = df_train.shape[0]\n",
    "X_valid_cnt = df_valid.shape[0]\n",
    "X_test_cnt = df_test.shape[0]\n",
    "\n",
    "X_all = df_all.text.values\n",
    "\n",
    "print('Train partition size: {}'.format(X_train_cnt))\n",
    "print('Valid partition size: {}'.format(X_valid_cnt))\n",
    "print('Test partition size: {}'.format(X_test_cnt))\n",
    "print('Total dataset size: {}'.format(X_all.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create token sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size = 67356\n",
      "CPU times: user 10.9 s, sys: 61 ms, total: 11 s\n",
      "Wall time: 11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# reduce vocabulary size to make problem manageable for available computing resources\n",
    "#SEQ_VOC = 50000\n",
    "#print('Number of tokens for sequences = {}'.format(SEQ_VOC))\n",
    "\n",
    "#tokenizer = Tokenizer(num_words=VOC_SIZE, filters='!\"*,./:;?@\\`|')\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_all)\n",
    "sequences = tokenizer.texts_to_sequences(X_all)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "VOC_SIZE = len(word_index)\n",
    "print('Vocabulary size = {}'.format(VOC_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3IAAAD8CAYAAAAyhZbUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x103953518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seq_len = [len(seq) for seq in sequences]\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 4))\n",
    "axes[0].boxplot(seq_len)\n",
    "axes[1].hist(seq_len, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = 50\n",
    "X_token_seq_all = pad_sequences(sequences, maxlen=MAX_SEQ_LEN, dtype='int32', padding='pre', truncating='post', value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize output labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = df_all.label.values\n",
    "label_dict = {label: no for no, label in enumerate(set(labels))}\n",
    "label_dict_inv = {no: label for label, no in label_dict.items()}\n",
    "number_of_classes = len(label_dict)\n",
    "\n",
    "# get labels as integers\n",
    "y_all = [label_dict[label] for label in labels]\n",
    "\n",
    "# change y to categorical (vectorize output)\n",
    "y_all = np.array([to_categorical(i, num_classes=number_of_classes) for i in y_all])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare embedding layer with pre-trained glove word vectors\n",
    "\n",
    "I use glove pre-trained (on Twiter) embeddings. <br> \n",
    "My code follows guidelines from Keras tutorial: <br>\n",
    "https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using embedding dim = 25\n",
      "Number of word vectors found: 1193514\n",
      "CPU times: user 12.8 s, sys: 380 ms, total: 13.2 s\n",
      "Wall time: 13.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# read pre-trained glove embeddings\n",
    "\n",
    "# create dictionary with word embeddings\n",
    "embedding_file = {}\n",
    "embedding_file[25] = 'glove/glove.twitter.27B.25d.txt'\n",
    "embedding_file[50] = 'glove/glove.twitter.27B.50d.txt'\n",
    "embedding_file[100] = 'glove/glove.twitter.27B.100d.txt'\n",
    "embedding_file[200] = 'glove/glove.twitter.27B.200d.txt'\n",
    "\n",
    "# set embedding dimension\n",
    "EMBEDDING_DIM = 25\n",
    "\n",
    "embeddings_index = {}\n",
    "print('Using embedding dim = {}'.format(EMBEDDING_DIM))\n",
    "\n",
    "f = open(embedding_file[EMBEDDING_DIM], 'r')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Number of word vectors found: {}'.format(len(embeddings_index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 69.7 ms, sys: 2.73 ms, total: 72.5 ms\n",
      "Wall time: 71.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# create matrix with embedding coefs for each word in vocabulary\n",
    "# row position of word representation in the matrix will be the word number\n",
    "\n",
    "# initiazes matrix with zeros\n",
    "embedding_matrix = np.zeros((VOC_SIZE + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 50, 25)            1683925   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 200)               180800    \n",
      "_________________________________________________________________\n",
      "sentence_vector_1 (Dense)    (None, 25)                5025      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "sentence_vector_2 (Dense)    (None, 5)                 130       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 30        \n",
      "=================================================================\n",
      "Total params: 1,869,910\n",
      "Trainable params: 185,985\n",
      "Non-trainable params: 1,683,925\n",
      "_________________________________________________________________\n",
      "Train on 180040 samples, validate on 30212 samples\n",
      "Epoch 1/20\n",
      "180040/180040 [==============================] - 217s 1ms/step - loss: 3.9193 - acc: 0.3924 - val_loss: 3.5636 - val_acc: 0.6058\n",
      "Epoch 2/20\n",
      "180040/180040 [==============================] - 212s 1ms/step - loss: 3.6847 - acc: 0.4903 - val_loss: 3.4458 - val_acc: 0.6747\n",
      "Epoch 3/20\n",
      "180040/180040 [==============================] - 210s 1ms/step - loss: 3.6154 - acc: 0.5440 - val_loss: 3.3768 - val_acc: 0.7110\n",
      "Epoch 4/20\n",
      "180040/180040 [==============================] - 212s 1ms/step - loss: 3.5738 - acc: 0.5914 - val_loss: 3.3204 - val_acc: 0.7379\n",
      "Epoch 5/20\n",
      "180040/180040 [==============================] - 214s 1ms/step - loss: 3.5522 - acc: 0.6140 - val_loss: 3.2830 - val_acc: 0.7545\n",
      "Epoch 6/20\n",
      "180040/180040 [==============================] - 215s 1ms/step - loss: 3.5277 - acc: 0.6314 - val_loss: 3.2673 - val_acc: 0.7659\n",
      "Epoch 7/20\n",
      "180040/180040 [==============================] - 217s 1ms/step - loss: 3.5084 - acc: 0.6423 - val_loss: 3.2475 - val_acc: 0.7628\n",
      "Epoch 8/20\n",
      "180040/180040 [==============================] - 215s 1ms/step - loss: 3.4934 - acc: 0.6489 - val_loss: 3.2417 - val_acc: 0.7746\n",
      "Epoch 9/20\n",
      "180040/180040 [==============================] - 215s 1ms/step - loss: 3.5004 - acc: 0.6385 - val_loss: 3.2440 - val_acc: 0.7668\n",
      "CPU times: user 2h 54min 12s, sys: 30min 24s, total: 3h 24min 37s\n",
      "Wall time: 32min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Embedding, Input, LSTM, Flatten, Dropout, Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "embedding_layer = Embedding(VOC_SIZE + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQ_LEN,\n",
    "                            trainable=False)\n",
    "\n",
    "sequence_input = Input(shape=(MAX_SEQ_LEN,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "lstm = LSTM(units=200, return_sequences=False)(embedded_sequences)\n",
    "D1 = Dense(25, activation='relu', name='sentence_vector_1')(lstm)\n",
    "D1 = Dropout(0.5)(D1)\n",
    "D1 = Dense(5, activation='relu', name='sentence_vector_2')(D1)\n",
    "D1 = Dropout(0.5)(D1)\n",
    "preds = Dense(len(label_dict), \\\n",
    "              kernel_regularizer=regularizers.l2(0.01), \\\n",
    "              activity_regularizer=regularizers.l1(0.01), \\\n",
    "              activation='softmax')(D1)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# learn\n",
    "model.fit(X_token_seq_all[:X_train_cnt], y_all[:X_train_cnt], \\\n",
    "          validation_data=(X_token_seq_all[X_train_cnt:(X_train_cnt+X_valid_cnt)], \\\n",
    "                                     y_all[X_train_cnt:(X_train_cnt+X_valid_cnt)]), \\\n",
    "          callbacks=[EarlyStopping(patience=1, monitor='val_loss')], \\\n",
    "          verbose=1, epochs=20, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy = 0.7589845694375311\n"
     ]
    }
   ],
   "source": [
    "y_hat = np.argmax(model.predict(X_token_seq_all[-X_test_cnt:]), axis=1)\n",
    "y_true = np.argmax(y_all[-X_test_cnt:], axis=1)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Test accuracy = {}'.format(accuracy_score(y_true, y_hat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('input/task1_LSTM.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data used as input to the model\n",
    "\n",
    "1. Token sequences\n",
    "2. Labels in vectorized form\n",
    "3. Word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_token_seq_all = pd.DataFrame(X_token_seq_all) \n",
    "df_token_seq_all.to_csv('input/df_token_seq_all.csv', index=None)\n",
    "df_y_all = pd.DataFrame(y_all)\n",
    "df_y_all.to_csv('input/df_y_all.csv', index=None)\n",
    "df_embedding_matrix = pd.DataFrame(embedding_matrix)\n",
    "df_embedding_matrix.to_csv('input/df_embedding_matrix.csv', index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
